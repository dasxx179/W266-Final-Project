{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT Preprocess.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SKQ4bH7qMGrA"
      },
      "source": [
        "\n",
        "<h1>Taking advantage of Colab Pro</h1> \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "23TOba33L4qf",
        "outputId": "14e4f051-f6e9-4d19-c82f-16600d185d40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime → \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Apr  3 04:26:41 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.64.00    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "V1G82GuO-tez",
        "outputId": "eddf3595-7cf6-4683-ce64-966a6c1dc893",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        }
      },
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('To enable a high-RAM runtime, select the Runtime → \"Change runtime type\"')\n",
        "  print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n",
        "  print('re-execute this cell.')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Your runtime has 27.4 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjIv81PNZDtB",
        "colab_type": "code",
        "outputId": "1db8b50d-45df-4b55-a4de-e3afcfb3a8f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135
        }
      },
      "source": [
        "import torch \n",
        "import numpy \n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "print(\"Imported Libraries\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "Imported Libraries\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2PobLR9ac1s",
        "colab_type": "code",
        "outputId": "0638084f-385b-4e86-b615-a554d23b6ff4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 779
        }
      },
      "source": [
        "!git clone https://github.com/huggingface/transformers.git\n",
        "!cd transformers\n",
        "!pip install transformers"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'transformers'...\n",
            "remote: Enumerating objects: 54, done.\u001b[K\n",
            "remote: Counting objects: 100% (54/54), done.\u001b[K\n",
            "remote: Compressing objects: 100% (40/40), done.\u001b[K\n",
            "remote: Total 23706 (delta 22), reused 31 (delta 8), pack-reused 23652\u001b[K\n",
            "Receiving objects: 100% (23706/23706), 13.68 MiB | 8.31 MiB/s, done.\n",
            "Resolving deltas: 100% (16929/16929), done.\n",
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/37/ba/dda44bbf35b071441635708a3dd568a5ca6bf29f77389f7c7c6818ae9498/transformers-2.7.0-py3-none-any.whl (544kB)\n",
            "\u001b[K     |████████████████████████████████| 552kB 1.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 74.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
            "\u001b[K     |████████████████████████████████| 870kB 78.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 65.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.31)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.31 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.31)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.31->boto3->transformers) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.31->boto3->transformers) (0.15.2)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=7c7371094cca3e497e2d068163abd999cb6923820b0d2d9bdc5bc493122237ac\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, sentencepiece, transformers\n",
            "Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 tokenizers-0.5.2 transformers-2.7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8eMTgw_CA9F",
        "colab_type": "text"
      },
      "source": [
        "# Train BERT "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgladAhhvaE7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks/W266\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amjRUKEy6s8z",
        "colab_type": "code",
        "outputId": "fada8d62-4c8d-4478-9da7-cc62b1e5d91f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " bert_cached_lm_510_hundredParsed.csv   L3\n",
            " bert_cached_lm_510_L2_7topics.txt      L3_from_pretrain.py\n",
            "'BERT Preprocess.ipynb'\t\t        L3Output\n",
            " eightyParsed.csv\t\t        nextTwentyParsed.csv\n",
            " eightyThousand2e-5Model\t        oneHundredRow2e-5Model\n",
            " hundredParsed.csv\t\t        outputDirectory\n",
            " L1Models16\t\t\t        parsedCorpus.csv\n",
            " L2_7topics.txt\t\t\t        preTrainOutput\n",
            " L2Models\t\t\t        run_language_modeling.py\n",
            " L2Models1E-0416Batch\t\t        runs\n",
            " L2Models1E-048Batch\t\t        transformers\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykGchcfBTpSy",
        "colab_type": "text"
      },
      "source": [
        "# Fine-Tune Data!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGsdtyY8ZkHA",
        "colab_type": "code",
        "outputId": "33f03586-b950-40d0-8d7c-1d95ea7d56fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python L3_from_pretrain.py --data_dir \"/content/drive/My Drive/Colab Notebooks/W266/L3/L3_Bert_7topics\" \\\n",
        "--model_name_or_path \"bert-base-uncased\" \\\n",
        "--model_type \"bert\" --model_dir \"/content/drive/My Drive/Colab Notebooks/W266/L3Output\" \\\n",
        "--num_train_epochs 8 \\\n",
        "--num_labels 14 \\\n",
        "--learning_rate 1e-4 \\\n",
        "--adam_epsilon 1e-9 \\\n",
        "--do_train"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-04-03 04:32:18.806337: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "04/03/2020 04:32:20 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "Preprocessing Goes here\n",
            "Directory: /content/drive/My Drive/Colab Notebooks/W266/L3/L3_Bert_7topics\n",
            "   id  ...                                               text\n",
            "0   0  ...        The US doesn’t just sell military arsenals.\n",
            "1   1  ...  Under current plans, the Army will recruit an ...\n",
            "2   2  ...  Whatever label you attach to their strategy, t...\n",
            "3   3  ...  Otherwise, the money will have to be allocated...\n",
            "4   4  ...  Open immigration policies and efforts do not a...\n",
            "\n",
            "[5 rows x 4 columns]\n",
            "Loading BERT tokenizer...\n",
            "04/03/2020 04:32:22 - INFO - filelock -   Lock 139861056964256 acquired on /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084.lock\n",
            "04/03/2020 04:32:22 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmplphexvgr\n",
            "Downloading: 100% 232k/232k [00:00<00:00, 415kB/s]\n",
            "04/03/2020 04:32:23 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt in cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "04/03/2020 04:32:23 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "04/03/2020 04:32:23 - INFO - filelock -   Lock 139861056964256 released on /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084.lock\n",
            "04/03/2020 04:32:23 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "Creating Attention Masks\n",
            "Created train dataset and loader\n",
            "Preprocessing Goes here\n",
            "Directory: /content/drive/My Drive/Colab Notebooks/W266/L3/L3_Bert_7topics\n",
            "     id  ...                                               text\n",
            "0  8988  ...            Did I mistakenly use the word “person”?\n",
            "1  8989  ...            In this, I am like most American women.\n",
            "2  8990  ...  Arguing from the Law  Roe v. Wade  Most people...\n",
            "3  8991  ...  The availability of legal abortion has had bro...\n",
            "4  8992  ...  And, if they can pass what they have proposed ...\n",
            "\n",
            "[5 rows x 4 columns]\n",
            "Loading BERT tokenizer...\n",
            "04/03/2020 04:32:29 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "Creating Attention Masks\n",
            "Created dev dataset and loader\n",
            "04/03/2020 04:32:30 - INFO - filelock -   Lock 139861056963752 acquired on /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.8f56353af4a709bf5ff0fbc915d8f5b42bfff892cbb6ac98c3c45f481a03c685.lock\n",
            "04/03/2020 04:32:30 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmp5i7b9me3\n",
            "Downloading: 100% 361/361 [00:00<00:00, 289kB/s]\n",
            "04/03/2020 04:32:31 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json in cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.8f56353af4a709bf5ff0fbc915d8f5b42bfff892cbb6ac98c3c45f481a03c685\n",
            "04/03/2020 04:32:31 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.8f56353af4a709bf5ff0fbc915d8f5b42bfff892cbb6ac98c3c45f481a03c685\n",
            "04/03/2020 04:32:31 - INFO - filelock -   Lock 139861056963752 released on /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.8f56353af4a709bf5ff0fbc915d8f5b42bfff892cbb6ac98c3c45f481a03c685.lock\n",
            "04/03/2020 04:32:31 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.8f56353af4a709bf5ff0fbc915d8f5b42bfff892cbb6ac98c3c45f481a03c685\n",
            "04/03/2020 04:32:31 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
            "  \"_num_labels\": 14,\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": null,\n",
            "  \"decoder_start_token_id\": null,\n",
            "  \"do_sample\": false,\n",
            "  \"early_stopping\": false,\n",
            "  \"eos_token_id\": null,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\",\n",
            "    \"4\": \"LABEL_4\",\n",
            "    \"5\": \"LABEL_5\",\n",
            "    \"6\": \"LABEL_6\",\n",
            "    \"7\": \"LABEL_7\",\n",
            "    \"8\": \"LABEL_8\",\n",
            "    \"9\": \"LABEL_9\",\n",
            "    \"10\": \"LABEL_10\",\n",
            "    \"11\": \"LABEL_11\",\n",
            "    \"12\": \"LABEL_12\",\n",
            "    \"13\": \"LABEL_13\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"is_encoder_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_10\": 10,\n",
            "    \"LABEL_11\": 11,\n",
            "    \"LABEL_12\": 12,\n",
            "    \"LABEL_13\": 13,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3,\n",
            "    \"LABEL_4\": 4,\n",
            "    \"LABEL_5\": 5,\n",
            "    \"LABEL_6\": 6,\n",
            "    \"LABEL_7\": 7,\n",
            "    \"LABEL_8\": 8,\n",
            "    \"LABEL_9\": 9\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"min_length\": 0,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"no_repeat_ngram_size\": 0,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"prefix\": null,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"task_specific_params\": null,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "04/03/2020 04:32:32 - INFO - filelock -   Lock 139861057040224 acquired on /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157.lock\n",
            "04/03/2020 04:32:32 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmp2d9ugzyn\n",
            "Downloading: 100% 440M/440M [00:35<00:00, 12.4MB/s]\n",
            "04/03/2020 04:33:08 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin in cache at /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "04/03/2020 04:33:08 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "04/03/2020 04:33:08 - INFO - filelock -   Lock 139861057040224 released on /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157.lock\n",
            "04/03/2020 04:33:08 - INFO - transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "04/03/2020 04:33:11 - INFO - transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
            "04/03/2020 04:33:11 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "04/03/2020 04:33:26 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-09, data_dir='/content/drive/My Drive/Colab Notebooks/W266/L3/L3_Bert_7topics', device=device(type='cuda'), do_eval=False, do_train=True, fp16=False, learning_rate=0.0001, local_rank=-1, model_dir='/content/drive/My Drive/Colab Notebooks/W266/L3Output', model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, num_labels=14, num_train_epochs=8, per_gpu_train_batch_size=8, seed=101)\n",
            "Training Goes here\n",
            "\n",
            "======== Epoch 1 / 8 ========\n",
            "Training...\n",
            "  Batch    40  of    281.    Elapsed: 0:00:16.\n",
            "  Batch    80  of    281.    Elapsed: 0:00:31.\n",
            "  Batch   120  of    281.    Elapsed: 0:00:47.\n",
            "  Batch   160  of    281.    Elapsed: 0:01:02.\n",
            "  Batch   200  of    281.    Elapsed: 0:01:18.\n",
            "  Batch   240  of    281.    Elapsed: 0:01:33.\n",
            "  Batch   280  of    281.    Elapsed: 0:01:48.\n",
            "\n",
            "  F1: 0.52\n",
            "  Average training loss: 1.31\n",
            "  Training epoch took: 0:01:49\n",
            "\n",
            "Running Validation...\n",
            "  F1: 0.59\n",
            "  Accuracy: 0.59\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 2 / 8 ========\n",
            "Training...\n",
            "  Batch    40  of    281.    Elapsed: 0:00:15.\n",
            "  Batch    80  of    281.    Elapsed: 0:00:31.\n",
            "  Batch   120  of    281.    Elapsed: 0:00:46.\n",
            "  Batch   160  of    281.    Elapsed: 0:01:02.\n",
            "  Batch   200  of    281.    Elapsed: 0:01:17.\n",
            "  Batch   240  of    281.    Elapsed: 0:01:32.\n",
            "  Batch   280  of    281.    Elapsed: 0:01:48.\n",
            "\n",
            "  F1: 0.68\n",
            "  Average training loss: 0.83\n",
            "  Training epoch took: 0:01:48\n",
            "\n",
            "Running Validation...\n",
            "  F1: 0.68\n",
            "  Accuracy: 0.68\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 3 / 8 ========\n",
            "Training...\n",
            "  Batch    40  of    281.    Elapsed: 0:00:15.\n",
            "  Batch    80  of    281.    Elapsed: 0:00:31.\n",
            "  Batch   120  of    281.    Elapsed: 0:00:46.\n",
            "  Batch   160  of    281.    Elapsed: 0:01:02.\n",
            "  Batch   200  of    281.    Elapsed: 0:01:17.\n",
            "  Batch   240  of    281.    Elapsed: 0:01:32.\n",
            "  Batch   280  of    281.    Elapsed: 0:01:48.\n",
            "\n",
            "  F1: 0.83\n",
            "  Average training loss: 0.47\n",
            "  Training epoch took: 0:01:48\n",
            "\n",
            "Running Validation...\n",
            "  F1: 0.69\n",
            "  Accuracy: 0.69\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 4 / 8 ========\n",
            "Training...\n",
            "  Batch    40  of    281.    Elapsed: 0:00:15.\n",
            "  Batch    80  of    281.    Elapsed: 0:00:31.\n",
            "  Batch   120  of    281.    Elapsed: 0:00:46.\n",
            "  Batch   160  of    281.    Elapsed: 0:01:02.\n",
            "  Batch   200  of    281.    Elapsed: 0:01:17.\n",
            "  Batch   240  of    281.    Elapsed: 0:01:33.\n",
            "  Batch   280  of    281.    Elapsed: 0:01:48.\n",
            "\n",
            "  F1: 0.93\n",
            "  Average training loss: 0.22\n",
            "  Training epoch took: 0:01:48\n",
            "\n",
            "Running Validation...\n",
            "  F1: 0.69\n",
            "  Accuracy: 0.69\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 5 / 8 ========\n",
            "Training...\n",
            "  Batch    40  of    281.    Elapsed: 0:00:15.\n",
            "  Batch    80  of    281.    Elapsed: 0:00:31.\n",
            "  Batch   120  of    281.    Elapsed: 0:00:46.\n",
            "  Batch   160  of    281.    Elapsed: 0:01:02.\n",
            "  Batch   200  of    281.    Elapsed: 0:01:17.\n",
            "  Batch   240  of    281.    Elapsed: 0:01:32.\n",
            "  Batch   280  of    281.    Elapsed: 0:01:48.\n",
            "\n",
            "  F1: 0.96\n",
            "  Average training loss: 0.11\n",
            "  Training epoch took: 0:01:48\n",
            "\n",
            "Running Validation...\n",
            "  F1: 0.69\n",
            "  Accuracy: 0.69\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 6 / 8 ========\n",
            "Training...\n",
            "  Batch    40  of    281.    Elapsed: 0:00:15.\n",
            "  Batch    80  of    281.    Elapsed: 0:00:31.\n",
            "  Batch   120  of    281.    Elapsed: 0:00:46.\n",
            "  Batch   160  of    281.    Elapsed: 0:01:01.\n",
            "  Batch   200  of    281.    Elapsed: 0:01:17.\n",
            "  Batch   240  of    281.    Elapsed: 0:01:32.\n",
            "  Batch   280  of    281.    Elapsed: 0:01:48.\n",
            "\n",
            "  F1: 0.98\n",
            "  Average training loss: 0.06\n",
            "  Training epoch took: 0:01:48\n",
            "\n",
            "Running Validation...\n",
            "  F1: 0.70\n",
            "  Accuracy: 0.70\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 7 / 8 ========\n",
            "Training...\n",
            "  Batch    40  of    281.    Elapsed: 0:00:15.\n",
            "  Batch    80  of    281.    Elapsed: 0:00:31.\n",
            "  Batch   120  of    281.    Elapsed: 0:00:46.\n",
            "  Batch   160  of    281.    Elapsed: 0:01:02.\n",
            "  Batch   200  of    281.    Elapsed: 0:01:17.\n",
            "  Batch   240  of    281.    Elapsed: 0:01:32.\n",
            "  Batch   280  of    281.    Elapsed: 0:01:48.\n",
            "\n",
            "  F1: 0.99\n",
            "  Average training loss: 0.04\n",
            "  Training epoch took: 0:01:48\n",
            "\n",
            "Running Validation...\n",
            "  F1: 0.70\n",
            "  Accuracy: 0.70\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 8 / 8 ========\n",
            "Training...\n",
            "  Batch    40  of    281.    Elapsed: 0:00:15.\n",
            "  Batch    80  of    281.    Elapsed: 0:00:31.\n",
            "  Batch   120  of    281.    Elapsed: 0:00:46.\n",
            "  Batch   160  of    281.    Elapsed: 0:01:01.\n",
            "  Batch   200  of    281.    Elapsed: 0:01:17.\n",
            "  Batch   240  of    281.    Elapsed: 0:01:32.\n",
            "  Batch   280  of    281.    Elapsed: 0:01:48.\n",
            "\n",
            "  F1: 0.99\n",
            "  Average training loss: 0.02\n",
            "  Training epoch took: 0:01:48\n",
            "\n",
            "Running Validation...\n",
            "  F1: 0.70\n",
            "  Accuracy: 0.70\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "F1 Train: [0.516243880729862, 0.6841344014241211, 0.82688028482421, 0.9273475745438362, 0.9642857142857143, 0.9824210057854917, 0.988206497552292, 0.9897641299510458]\n",
            "F1 Dev: [0.5915915915915916, 0.6846846846846847, 0.6906906906906907, 0.6906906906906907, 0.6886886886886887, 0.7047047047047047, 0.6956956956956957, 0.6996996996996997]\n",
            "Training complete!\n",
            "saved model path\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wdvmi8OEvwD",
        "colab_type": "code",
        "outputId": "41182b1d-e37d-46ea-a771-908934d51377",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python3 run_language_modeling.py \\\n",
        "--train_data_file \"/content/drive/My Drive/Colab Notebooks/W266/L2_7topics.txt\" \\\n",
        "--output_dir \"/content/drive/My Drive/Colab Notebooks/W266/L2Models1E-0416Batch/4Epoch\" \\\n",
        "--model_type \"bert\" \\\n",
        "--mlm \\\n",
        "--model_name_or_path \"/content/drive/My Drive/Colab Notebooks/W266/L1Models16/oneHundredRow2e-516Batch4Epoch\" \\\n",
        "--num_train_epochs 4 \\\n",
        "--learning_rate 1e-4 \\\n",
        "--per_gpu_train_batch_size 16 \\\n",
        "--do_train \\\n",
        "--block_size 512 \\\n",
        "--seed 42"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-04-01 16:27:16.472199: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "04/01/2020 16:27:18 - WARNING - __main__ -   Process rank: -1, device: cpu, n_gpu: 0, distributed training: False, 16-bits training: False\n",
            "04/01/2020 16:27:19 - INFO - transformers.configuration_utils -   loading configuration file /content/drive/My Drive/Colab Notebooks/W266/L1Models16/oneHundredRow2e-516Batch4Epoch/config.json\n",
            "04/01/2020 16:27:19 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
            "  \"_num_labels\": 2,\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": null,\n",
            "  \"decoder_start_token_id\": null,\n",
            "  \"do_sample\": false,\n",
            "  \"early_stopping\": false,\n",
            "  \"eos_token_id\": null,\n",
            "  \"eos_token_ids\": null,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"is_encoder_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"min_length\": 0,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"no_repeat_ngram_size\": 0,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": null,\n",
            "  \"prefix\": null,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"task_specific_params\": null,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "04/01/2020 16:27:19 - INFO - transformers.tokenization_utils -   Model name '/content/drive/My Drive/Colab Notebooks/W266/L1Models16/oneHundredRow2e-516Batch4Epoch' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming '/content/drive/My Drive/Colab Notebooks/W266/L1Models16/oneHundredRow2e-516Batch4Epoch' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
            "04/01/2020 16:27:19 - INFO - transformers.tokenization_utils -   Didn't find file /content/drive/My Drive/Colab Notebooks/W266/L1Models16/oneHundredRow2e-516Batch4Epoch/added_tokens.json. We won't load it.\n",
            "04/01/2020 16:27:19 - INFO - transformers.tokenization_utils -   loading file /content/drive/My Drive/Colab Notebooks/W266/L1Models16/oneHundredRow2e-516Batch4Epoch/vocab.txt\n",
            "04/01/2020 16:27:19 - INFO - transformers.tokenization_utils -   loading file None\n",
            "04/01/2020 16:27:19 - INFO - transformers.tokenization_utils -   loading file /content/drive/My Drive/Colab Notebooks/W266/L1Models16/oneHundredRow2e-516Batch4Epoch/special_tokens_map.json\n",
            "04/01/2020 16:27:19 - INFO - transformers.tokenization_utils -   loading file /content/drive/My Drive/Colab Notebooks/W266/L1Models16/oneHundredRow2e-516Batch4Epoch/tokenizer_config.json\n",
            "04/01/2020 16:27:20 - INFO - transformers.modeling_utils -   loading weights file /content/drive/My Drive/Colab Notebooks/W266/L1Models16/oneHundredRow2e-516Batch4Epoch/pytorch_model.bin\n",
            "04/01/2020 16:27:28 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, block_size=512, cache_dir=None, config_name=None, device=device(type='cpu'), do_eval=False, do_train=True, eval_all_checkpoints=False, eval_data_file=None, evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=0.0001, line_by_line=False, local_rank=-1, logging_steps=500, max_grad_norm=1.0, max_steps=-1, mlm=True, mlm_probability=0.15, model_name_or_path='/content/drive/My Drive/Colab Notebooks/W266/L1Models16/oneHundredRow2e-516Batch4Epoch', model_type='bert', n_gpu=0, no_cuda=False, num_train_epochs=4.0, output_dir='/content/drive/My Drive/Colab Notebooks/W266/L2Models1E-0416Batch/4Epoch', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=4, per_gpu_train_batch_size=16, save_steps=500, save_total_limit=None, seed=42, server_ip='', server_port='', should_continue=False, tokenizer_name=None, train_data_file='/content/drive/My Drive/Colab Notebooks/W266/L2_7topics.txt', warmup_steps=0, weight_decay=0.0)\n",
            "04/01/2020 16:27:28 - INFO - __main__ -   Loading features from cached file /content/drive/My Drive/Colab Notebooks/W266/bert_cached_lm_510_L2_7topics.txt\n",
            "04/01/2020 16:27:28 - INFO - __main__ -   ***** Running training *****\n",
            "04/01/2020 16:27:28 - INFO - __main__ -     Num examples = 2901\n",
            "04/01/2020 16:27:28 - INFO - __main__ -     Num Epochs = 4\n",
            "04/01/2020 16:27:28 - INFO - __main__ -     Instantaneous batch size per GPU = 16\n",
            "04/01/2020 16:27:28 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "04/01/2020 16:27:28 - INFO - __main__ -     Gradient Accumulation steps = 1\n",
            "04/01/2020 16:27:28 - INFO - __main__ -     Total optimization steps = 728\n",
            "04/01/2020 16:27:28 - INFO - __main__ -     Starting fine-tuning.\n",
            "Epoch:   0% 0/4 [00:00<?, ?it/s]\n",
            "Iteration:   0% 0/182 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   1% 1/182 [00:20<1:02:58, 20.88s/it]\u001b[A\n",
            "Iteration:   1% 2/182 [00:33<55:36, 18.54s/it]  \u001b[A\n",
            "Iteration:   2% 3/182 [00:46<49:47, 16.69s/it]\u001b[A\n",
            "Iteration:   2% 4/182 [00:58<45:10, 15.23s/it]\u001b[A\n",
            "Iteration:   3% 5/182 [01:09<41:36, 14.10s/it]\u001b[A\n",
            "Iteration:   3% 6/182 [01:21<39:07, 13.34s/it]\u001b[A\n",
            "Iteration:   4% 7/182 [01:32<37:17, 12.79s/it]\u001b[A\n",
            "Iteration:   4% 8/182 [01:44<35:55, 12.39s/it]\u001b[A\n",
            "Iteration:   5% 9/182 [01:55<35:00, 12.14s/it]\u001b[A\n",
            "Iteration:   5% 10/182 [02:07<34:21, 11.99s/it]\u001b[A\n",
            "Iteration:   6% 11/182 [02:18<33:52, 11.89s/it]\u001b[A\n",
            "Iteration:   7% 12/182 [02:30<33:27, 11.81s/it]\u001b[A\n",
            "Iteration:   7% 13/182 [02:42<33:10, 11.78s/it]\u001b[A\n",
            "Iteration:   8% 14/182 [02:53<32:50, 11.73s/it]\u001b[A\n",
            "Iteration:   8% 15/182 [03:05<32:34, 11.70s/it]\u001b[A\n",
            "Iteration:   9% 16/182 [03:17<32:23, 11.71s/it]\u001b[A\n",
            "Iteration:   9% 17/182 [03:28<31:59, 11.63s/it]\u001b[A\n",
            "Iteration:  10% 18/182 [03:40<31:37, 11.57s/it]\u001b[A\n",
            "Iteration:  10% 19/182 [03:51<31:31, 11.60s/it]\u001b[A\n",
            "Iteration:  11% 20/182 [04:03<31:13, 11.56s/it]\u001b[A\n",
            "Iteration:  12% 21/182 [04:14<31:03, 11.58s/it]\u001b[A\n",
            "Iteration:  12% 22/182 [04:26<30:50, 11.56s/it]\u001b[A\n",
            "Iteration:  13% 23/182 [04:38<30:49, 11.63s/it]\u001b[A\n",
            "Iteration:  13% 24/182 [04:50<30:53, 11.73s/it]\u001b[A\n",
            "Iteration:  14% 25/182 [05:01<30:41, 11.73s/it]\u001b[A\n",
            "Iteration:  14% 26/182 [05:13<30:31, 11.74s/it]\u001b[A\n",
            "Iteration:  15% 27/182 [05:26<30:56, 11.98s/it]\u001b[A\n",
            "Iteration:  15% 28/182 [05:39<31:42, 12.35s/it]\u001b[A\n",
            "Iteration:  16% 29/182 [05:52<32:04, 12.58s/it]\u001b[A\n",
            "Iteration:  16% 30/182 [06:04<31:30, 12.44s/it]\u001b[A\n",
            "Iteration:  17% 31/182 [06:16<30:58, 12.31s/it]\u001b[A\n",
            "Iteration:  18% 32/182 [06:28<30:23, 12.16s/it]\u001b[A\n",
            "Iteration:  18% 33/182 [06:40<29:57, 12.06s/it]\u001b[A\n",
            "Iteration:  19% 34/182 [06:52<29:27, 11.94s/it]\u001b[A\n",
            "Iteration:  19% 35/182 [07:03<29:07, 11.89s/it]\u001b[A\n",
            "Iteration:  20% 36/182 [07:15<28:53, 11.88s/it]\u001b[A\n",
            "Iteration:  20% 37/182 [07:27<28:30, 11.80s/it]\u001b[A\n",
            "Iteration:  21% 38/182 [07:39<28:18, 11.79s/it]\u001b[A\n",
            "Iteration:  21% 39/182 [07:50<28:01, 11.76s/it]\u001b[A\n",
            "Iteration:  22% 40/182 [08:02<27:50, 11.77s/it]\u001b[A\n",
            "Iteration:  23% 41/182 [08:14<28:02, 11.93s/it]\u001b[A\n",
            "Iteration:  23% 42/182 [08:26<27:47, 11.91s/it]\u001b[A\n",
            "Iteration:  24% 43/182 [08:38<27:45, 11.98s/it]\u001b[A\n",
            "Iteration:  24% 44/182 [08:51<27:48, 12.09s/it]\u001b[A\n",
            "Iteration:  25% 45/182 [09:02<27:22, 11.99s/it]\u001b[A\n",
            "Iteration:  25% 46/182 [09:14<26:51, 11.85s/it]\u001b[A\n",
            "Iteration:  26% 47/182 [09:26<26:33, 11.80s/it]\u001b[A\n",
            "Iteration:  26% 48/182 [09:37<26:18, 11.78s/it]\u001b[A\n",
            "Iteration:  27% 49/182 [09:49<26:13, 11.83s/it]\u001b[A\n",
            "Iteration:  27% 50/182 [10:01<26:03, 11.84s/it]\u001b[A\n",
            "Iteration:  28% 51/182 [10:13<25:56, 11.88s/it]\u001b[A\n",
            "Iteration:  29% 52/182 [10:25<25:50, 11.93s/it]\u001b[A\n",
            "Iteration:  29% 53/182 [10:37<25:40, 11.94s/it]\u001b[A\n",
            "Iteration:  30% 54/182 [10:50<25:57, 12.17s/it]\u001b[A\n",
            "Iteration:  30% 55/182 [11:03<26:07, 12.34s/it]\u001b[A\n",
            "Iteration:  31% 56/182 [11:14<25:37, 12.20s/it]\u001b[A\n",
            "Iteration:  31% 57/182 [11:26<25:06, 12.05s/it]\u001b[A\n",
            "Iteration:  32% 58/182 [11:38<24:59, 12.09s/it]\u001b[A\n",
            "Iteration:  32% 59/182 [11:50<24:42, 12.06s/it]\u001b[A\n",
            "Iteration:  33% 60/182 [12:02<24:26, 12.02s/it]\u001b[A\n",
            "Iteration:  34% 61/182 [12:14<24:11, 11.99s/it]\u001b[A\n",
            "Iteration:  34% 62/182 [12:26<23:49, 11.91s/it]\u001b[A\n",
            "Iteration:  35% 63/182 [12:38<23:31, 11.86s/it]\u001b[A\n",
            "Iteration:  35% 64/182 [12:49<23:13, 11.81s/it]\u001b[A\n",
            "Iteration:  36% 65/182 [13:01<23:01, 11.81s/it]\u001b[A\n",
            "Iteration:  36% 66/182 [13:13<22:48, 11.80s/it]\u001b[A\n",
            "Iteration:  37% 67/182 [13:25<22:32, 11.76s/it]\u001b[A\n",
            "Iteration:  37% 68/182 [13:37<22:33, 11.87s/it]\u001b[A\n",
            "Iteration:  38% 69/182 [13:49<22:29, 11.95s/it]\u001b[A\n",
            "Iteration:  38% 70/182 [14:01<22:22, 11.98s/it]\u001b[A\n",
            "Iteration:  39% 71/182 [14:13<22:08, 11.97s/it]\u001b[A\n",
            "Iteration:  40% 72/182 [14:27<23:06, 12.60s/it]\u001b[A\n",
            "Iteration:  40% 73/182 [14:43<24:46, 13.64s/it]\u001b[A\n",
            "Iteration:  41% 74/182 [14:59<25:34, 14.21s/it]\u001b[A\n",
            "Iteration:  41% 75/182 [15:14<25:50, 14.49s/it]\u001b[A\n",
            "Iteration:  42% 76/182 [15:29<26:01, 14.73s/it]\u001b[A\n",
            "Iteration:  42% 77/182 [15:44<26:06, 14.92s/it]\u001b[A\n",
            "Iteration:  43% 78/182 [16:00<26:27, 15.27s/it]\u001b[A\n",
            "Iteration:  43% 79/182 [16:16<26:07, 15.22s/it]\u001b[A\n",
            "Iteration:  44% 80/182 [16:30<25:30, 15.00s/it]\u001b[A\n",
            "Iteration:  45% 81/182 [16:49<27:17, 16.22s/it]\u001b[A\n",
            "Iteration:  45% 82/182 [17:03<25:50, 15.51s/it]\u001b[A\n",
            "Iteration:  46% 83/182 [17:22<27:32, 16.69s/it]\u001b[A\n",
            "Iteration:  46% 84/182 [17:39<27:06, 16.60s/it]\u001b[A\n",
            "Iteration:  47% 85/182 [17:52<25:03, 15.49s/it]\u001b[A\n",
            "Iteration:  47% 86/182 [18:04<23:09, 14.48s/it]\u001b[A\n",
            "Iteration:  48% 87/182 [18:19<23:09, 14.63s/it]\u001b[A\n",
            "Iteration:  48% 88/182 [18:32<22:19, 14.25s/it]\u001b[A\n",
            "Iteration:  49% 89/182 [18:46<21:42, 14.00s/it]\u001b[A\n",
            "Iteration:  49% 90/182 [18:58<20:39, 13.48s/it]\u001b[A\n",
            "Iteration:  50% 91/182 [19:13<21:06, 13.92s/it]\u001b[A\n",
            "Iteration:  51% 92/182 [19:30<22:35, 15.06s/it]\u001b[A\n",
            "Iteration:  51% 93/182 [19:48<23:29, 15.83s/it]\u001b[A\n",
            "Iteration:  52% 94/182 [20:05<23:53, 16.30s/it]\u001b[A\n",
            "Iteration:  52% 95/182 [20:24<24:31, 16.91s/it]\u001b[A\n",
            "Iteration:  53% 96/182 [20:42<24:46, 17.28s/it]\u001b[A\n",
            "Iteration:  53% 97/182 [21:00<24:36, 17.37s/it]\u001b[A\n",
            "Iteration:  54% 98/182 [21:17<24:13, 17.30s/it]\u001b[A\n",
            "Iteration:  54% 99/182 [21:35<24:30, 17.72s/it]\u001b[A\n",
            "Iteration:  55% 100/182 [21:55<25:05, 18.35s/it]\u001b[A\n",
            "Iteration:  55% 101/182 [22:15<25:22, 18.80s/it]\u001b[A\n",
            "Iteration:  56% 102/182 [22:29<23:19, 17.49s/it]\u001b[A\n",
            "Iteration:  57% 103/182 [22:47<23:11, 17.61s/it]\u001b[A\n",
            "Iteration:  57% 104/182 [23:01<21:26, 16.49s/it]\u001b[A\n",
            "Iteration:  58% 105/182 [23:14<19:50, 15.46s/it]\u001b[A\n",
            "Iteration:  58% 106/182 [23:27<18:39, 14.73s/it]\u001b[A\n",
            "Iteration:  59% 107/182 [23:40<17:49, 14.26s/it]\u001b[A\n",
            "Iteration:  59% 108/182 [23:54<17:12, 13.95s/it]\u001b[A\n",
            "Iteration:  60% 109/182 [24:08<17:01, 13.99s/it]\u001b[A\n",
            "Iteration:  60% 110/182 [24:20<16:06, 13.42s/it]\u001b[A\n",
            "Iteration:  61% 111/182 [24:33<15:43, 13.28s/it]\u001b[A\n",
            "Iteration:  62% 112/182 [24:47<15:51, 13.60s/it]\u001b[A\n",
            "Iteration:  62% 113/182 [25:00<15:18, 13.30s/it]\u001b[A\n",
            "Iteration:  63% 114/182 [25:12<14:48, 13.06s/it]\u001b[A\n",
            "Iteration:  63% 115/182 [25:25<14:19, 12.83s/it]\u001b[A\n",
            "Iteration:  64% 116/182 [25:37<13:55, 12.65s/it]\u001b[A\n",
            "Iteration:  64% 117/182 [25:49<13:37, 12.57s/it]\u001b[A\n",
            "Iteration:  65% 118/182 [26:01<13:18, 12.48s/it]\u001b[A\n",
            "Iteration:  65% 119/182 [26:14<13:05, 12.46s/it]\u001b[A\n",
            "Iteration:  66% 120/182 [26:26<12:49, 12.42s/it]\u001b[A\n",
            "Iteration:  66% 121/182 [26:39<12:34, 12.38s/it]\u001b[A\n",
            "Iteration:  67% 122/182 [26:51<12:23, 12.38s/it]\u001b[A\n",
            "Iteration:  68% 123/182 [27:03<12:11, 12.40s/it]\u001b[A\n",
            "Iteration:  68% 124/182 [27:16<12:00, 12.42s/it]\u001b[A\n",
            "Iteration:  69% 125/182 [27:28<11:41, 12.30s/it]\u001b[A\n",
            "Iteration:  69% 126/182 [27:40<11:24, 12.22s/it]\u001b[A\n",
            "Iteration:  70% 127/182 [27:52<11:10, 12.19s/it]\u001b[A\n",
            "Iteration:  70% 128/182 [28:04<10:57, 12.18s/it]\u001b[A\n",
            "Iteration:  71% 129/182 [28:16<10:47, 12.21s/it]\u001b[A\n",
            "Iteration:  71% 130/182 [28:30<10:55, 12.61s/it]\u001b[A\n",
            "Iteration:  72% 131/182 [28:42<10:39, 12.53s/it]\u001b[A\n",
            "Iteration:  73% 132/182 [28:55<10:23, 12.46s/it]\u001b[A\n",
            "Iteration:  73% 133/182 [29:07<10:09, 12.43s/it]\u001b[A\n",
            "Iteration:  74% 134/182 [29:19<09:56, 12.43s/it]\u001b[A\n",
            "Iteration:  74% 135/182 [29:32<09:41, 12.38s/it]\u001b[A\n",
            "Iteration:  75% 136/182 [29:44<09:24, 12.26s/it]\u001b[A\n",
            "Iteration:  75% 137/182 [29:56<09:10, 12.23s/it]\u001b[A\n",
            "Iteration:  76% 138/182 [30:08<08:57, 12.22s/it]\u001b[A\n",
            "Iteration:  76% 139/182 [30:20<08:46, 12.24s/it]\u001b[A\n",
            "Iteration:  77% 140/182 [30:33<08:36, 12.29s/it]\u001b[A\n",
            "Iteration:  77% 141/182 [30:45<08:20, 12.22s/it]\u001b[A\n",
            "Iteration:  78% 142/182 [30:57<08:09, 12.23s/it]\u001b[A\n",
            "Iteration:  79% 143/182 [31:10<08:02, 12.37s/it]\u001b[A\n",
            "Iteration:  79% 144/182 [31:22<07:47, 12.30s/it]\u001b[A\n",
            "Iteration:  80% 145/182 [31:34<07:34, 12.27s/it]\u001b[A\n",
            "Iteration:  80% 146/182 [31:46<07:21, 12.28s/it]\u001b[A\n",
            "Iteration:  81% 147/182 [31:59<07:11, 12.34s/it]\u001b[A\n",
            "Iteration:  81% 148/182 [32:11<07:00, 12.38s/it]\u001b[A\n",
            "Iteration:  82% 149/182 [32:24<06:49, 12.41s/it]\u001b[A\n",
            "Iteration:  82% 150/182 [32:37<06:40, 12.51s/it]\u001b[A\n",
            "Iteration:  83% 151/182 [32:49<06:27, 12.49s/it]\u001b[A\n",
            "Iteration:  84% 152/182 [33:01<06:09, 12.32s/it]\u001b[A\n",
            "Iteration:  84% 153/182 [33:13<05:57, 12.32s/it]\u001b[A\n",
            "Iteration:  85% 154/182 [33:25<05:43, 12.28s/it]\u001b[A\n",
            "Iteration:  85% 155/182 [33:38<05:32, 12.30s/it]\u001b[A\n",
            "Iteration:  86% 156/182 [33:51<05:24, 12.49s/it]\u001b[A\n",
            "Iteration:  86% 157/182 [34:03<05:08, 12.32s/it]\u001b[A\n",
            "Iteration:  87% 158/182 [34:15<04:54, 12.27s/it]\u001b[A\n",
            "Iteration:  87% 159/182 [34:27<04:42, 12.30s/it]\u001b[A\n",
            "Iteration:  88% 160/182 [34:39<04:30, 12.28s/it]\u001b[A\n",
            "Iteration:  88% 161/182 [34:51<04:15, 12.17s/it]\u001b[A\n",
            "Iteration:  89% 162/182 [35:03<04:01, 12.10s/it]\u001b[A\n",
            "Iteration:  90% 163/182 [35:15<03:50, 12.11s/it]\u001b[A\n",
            "Iteration:  90% 164/182 [35:28<03:39, 12.21s/it]\u001b[A\n",
            "Iteration:  91% 165/182 [35:40<03:28, 12.24s/it]\u001b[A\n",
            "Iteration:  91% 166/182 [35:52<03:16, 12.25s/it]\u001b[A\n",
            "Iteration:  92% 167/182 [36:05<03:03, 12.21s/it]\u001b[A\n",
            "Iteration:  92% 168/182 [36:17<02:50, 12.21s/it]\u001b[A\n",
            "Iteration:  93% 169/182 [36:29<02:37, 12.15s/it]\u001b[A\n",
            "Iteration:  93% 170/182 [36:41<02:25, 12.15s/it]\u001b[A\n",
            "Iteration:  94% 171/182 [36:53<02:14, 12.25s/it]\u001b[A\n",
            "Iteration:  95% 172/182 [37:05<02:01, 12.20s/it]\u001b[A\n",
            "Iteration:  95% 173/182 [37:18<01:49, 12.19s/it]\u001b[A\n",
            "Iteration:  96% 174/182 [37:30<01:37, 12.17s/it]\u001b[A\n",
            "Iteration:  96% 175/182 [37:42<01:25, 12.20s/it]\u001b[A\n",
            "Iteration:  97% 176/182 [37:54<01:12, 12.16s/it]\u001b[A\n",
            "Iteration:  97% 177/182 [38:06<01:00, 12.19s/it]\u001b[A\n",
            "Iteration:  98% 178/182 [38:19<00:49, 12.32s/it]\u001b[A\n",
            "Iteration:  98% 179/182 [38:31<00:36, 12.24s/it]\u001b[A\n",
            "Iteration:  99% 180/182 [38:43<00:24, 12.27s/it]\u001b[A\n",
            "Iteration:  99% 181/182 [38:56<00:12, 12.34s/it]\u001b[A\n",
            "Iteration: 100% 182/182 [39:01<00:00, 12.86s/it]\n",
            "Epoch:  25% 1/4 [39:01<1:57:03, 2341.19s/it]\n",
            "Iteration:   0% 0/182 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   1% 1/182 [00:12<37:20, 12.38s/it]\u001b[A\n",
            "Iteration:   1% 2/182 [00:24<36:39, 12.22s/it]\u001b[A\n",
            "Iteration:   2% 3/182 [00:36<36:11, 12.13s/it]\u001b[A\n",
            "Iteration:   2% 4/182 [00:48<35:53, 12.10s/it]\u001b[A\n",
            "Iteration:   3% 5/182 [01:00<35:39, 12.09s/it]\u001b[A\n",
            "Iteration:   3% 6/182 [01:12<35:32, 12.12s/it]\u001b[A\n",
            "Iteration:   4% 7/182 [01:24<35:37, 12.21s/it]\u001b[A\n",
            "Iteration:   4% 8/182 [01:37<35:22, 12.20s/it]\u001b[A\n",
            "Iteration:   5% 9/182 [01:49<35:13, 12.22s/it]\u001b[A\n",
            "Iteration:   5% 10/182 [02:01<35:05, 12.24s/it]\u001b[A\n",
            "Iteration:   6% 11/182 [02:13<34:55, 12.26s/it]\u001b[A\n",
            "Iteration:   7% 12/182 [02:26<34:40, 12.24s/it]\u001b[A\n",
            "Iteration:   7% 13/182 [02:37<34:10, 12.13s/it]\u001b[A\n",
            "Iteration:   8% 14/182 [02:50<33:55, 12.12s/it]\u001b[A\n",
            "Iteration:   8% 15/182 [03:02<33:40, 12.10s/it]\u001b[A\n",
            "Iteration:   9% 16/182 [03:14<33:34, 12.13s/it]\u001b[A\n",
            "Iteration:   9% 17/182 [03:26<33:02, 12.02s/it]\u001b[A\n",
            "Iteration:  10% 18/182 [03:37<32:45, 11.99s/it]\u001b[A\n",
            "Iteration:  10% 19/182 [03:50<32:49, 12.09s/it]\u001b[A\n",
            "Iteration:  11% 20/182 [04:02<32:50, 12.17s/it]\u001b[A\n",
            "Iteration:  12% 21/182 [04:15<33:01, 12.31s/it]\u001b[A\n",
            "Iteration:  12% 22/182 [04:27<32:41, 12.26s/it]\u001b[A\n",
            "Iteration:  13% 23/182 [04:39<32:18, 12.19s/it]\u001b[A\n",
            "Iteration:  13% 24/182 [04:51<31:51, 12.10s/it]\u001b[A\n",
            "Iteration:  14% 25/182 [05:03<31:55, 12.20s/it]\u001b[A\n",
            "Iteration:  14% 26/182 [05:16<31:49, 12.24s/it]\u001b[A\n",
            "Iteration:  15% 27/182 [05:28<31:32, 12.21s/it]\u001b[A\n",
            "Iteration:  15% 28/182 [05:40<31:26, 12.25s/it]\u001b[A\n",
            "Iteration:  16% 29/182 [05:52<31:04, 12.19s/it]\u001b[A\n",
            "Iteration:  16% 30/182 [06:04<30:44, 12.13s/it]\u001b[A\n",
            "Iteration:  17% 31/182 [06:16<30:24, 12.08s/it]\u001b[A\n",
            "Iteration:  18% 32/182 [06:28<30:16, 12.11s/it]\u001b[A\n",
            "Iteration:  18% 33/182 [06:41<30:12, 12.17s/it]\u001b[A\n",
            "Iteration:  19% 34/182 [06:52<29:50, 12.10s/it]\u001b[A\n",
            "Iteration:  19% 35/182 [07:05<29:46, 12.15s/it]\u001b[A\n",
            "Iteration:  20% 36/182 [07:17<29:37, 12.18s/it]\u001b[A\n",
            "Iteration:  20% 37/182 [07:29<29:12, 12.09s/it]\u001b[A\n",
            "Iteration:  21% 38/182 [07:41<28:50, 12.02s/it]\u001b[A\n",
            "Iteration:  21% 39/182 [07:53<28:48, 12.08s/it]\u001b[A\n",
            "Iteration:  22% 40/182 [08:05<28:53, 12.21s/it]\u001b[A\n",
            "Iteration:  23% 41/182 [08:18<28:53, 12.29s/it]\u001b[A\n",
            "Iteration:  23% 42/182 [08:30<28:43, 12.31s/it]\u001b[A\n",
            "Iteration:  24% 43/182 [08:43<28:36, 12.35s/it]\u001b[A\n",
            "Iteration:  24% 44/182 [08:55<28:10, 12.25s/it]\u001b[A\n",
            "Iteration:  25% 45/182 [09:07<27:51, 12.20s/it]\u001b[A\n",
            "Iteration:  25% 46/182 [09:20<28:03, 12.38s/it]\u001b[A\n",
            "Iteration:  26% 47/182 [09:32<27:47, 12.35s/it]\u001b[A\n",
            "Iteration:  26% 48/182 [09:44<27:27, 12.30s/it]\u001b[A\n",
            "Iteration:  27% 49/182 [09:56<27:06, 12.23s/it]\u001b[A\n",
            "Iteration:  27% 50/182 [10:09<27:02, 12.29s/it]\u001b[A\n",
            "Iteration:  28% 51/182 [10:21<27:09, 12.44s/it]\u001b[A\n",
            "Iteration:  29% 52/182 [10:33<26:42, 12.33s/it]\u001b[A\n",
            "Iteration:  29% 53/182 [10:46<26:22, 12.27s/it]\u001b[A\n",
            "Iteration:  30% 54/182 [10:58<26:05, 12.23s/it]\u001b[A\n",
            "Iteration:  30% 55/182 [11:12<26:53, 12.70s/it]\u001b[A\n",
            "Iteration:  31% 56/182 [11:25<26:58, 12.84s/it]\u001b[A\n",
            "Iteration:  31% 57/182 [11:37<26:28, 12.71s/it]\u001b[A\n",
            "Iteration:  32% 58/182 [11:49<25:47, 12.48s/it]\u001b[A\n",
            "Iteration:  32% 59/182 [12:01<25:08, 12.27s/it]\u001b[A\n",
            "Iteration:  33% 60/182 [12:13<24:40, 12.13s/it]\u001b[A\n",
            "Iteration:  34% 61/182 [12:25<24:20, 12.07s/it]\u001b[A\n",
            "Iteration:  34% 62/182 [12:37<24:06, 12.05s/it]\u001b[A\n",
            "Iteration:  35% 63/182 [12:48<23:44, 11.97s/it]\u001b[A\n",
            "Iteration:  35% 64/182 [13:01<23:41, 12.05s/it]\u001b[A\n",
            "Iteration:  36% 65/182 [13:13<23:30, 12.06s/it]\u001b[A\n",
            "Iteration:  36% 66/182 [13:25<23:17, 12.05s/it]\u001b[A\n",
            "Iteration:  37% 67/182 [13:36<22:55, 11.96s/it]\u001b[A\n",
            "Iteration:  37% 68/182 [13:48<22:32, 11.87s/it]\u001b[A\n",
            "Iteration:  38% 69/182 [14:00<22:08, 11.75s/it]\u001b[A\n",
            "Iteration:  38% 70/182 [14:11<21:54, 11.74s/it]\u001b[A\n",
            "Iteration:  39% 71/182 [14:23<21:47, 11.78s/it]\u001b[A\n",
            "Iteration:  40% 72/182 [14:35<21:43, 11.85s/it]\u001b[A\n",
            "Iteration:  40% 73/182 [14:47<21:35, 11.89s/it]\u001b[A\n",
            "Iteration:  41% 74/182 [14:59<21:23, 11.88s/it]\u001b[A\n",
            "Iteration:  41% 75/182 [15:11<21:05, 11.82s/it]\u001b[A\n",
            "Iteration:  42% 76/182 [15:23<21:08, 11.97s/it]\u001b[A\n",
            "Iteration:  42% 77/182 [15:35<20:56, 11.97s/it]\u001b[A\n",
            "Iteration:  43% 78/182 [15:47<20:39, 11.92s/it]\u001b[A\n",
            "Iteration:  43% 79/182 [15:59<20:25, 11.90s/it]\u001b[A\n",
            "Iteration:  44% 80/182 [16:11<20:16, 11.93s/it]\u001b[A\n",
            "Iteration:  45% 81/182 [16:23<20:03, 11.92s/it]\u001b[A\n",
            "Iteration:  45% 82/182 [16:34<19:52, 11.92s/it]\u001b[A\n",
            "Iteration:  46% 83/182 [16:47<19:43, 11.96s/it]\u001b[A\n",
            "Iteration:  46% 84/182 [16:58<19:28, 11.92s/it]\u001b[A\n",
            "Iteration:  47% 85/182 [17:10<19:16, 11.93s/it]\u001b[A\n",
            "Iteration:  47% 86/182 [17:22<19:01, 11.89s/it]\u001b[A\n",
            "Iteration:  48% 87/182 [17:34<18:48, 11.88s/it]\u001b[A\n",
            "Iteration:  48% 88/182 [17:46<18:34, 11.85s/it]\u001b[A\n",
            "Iteration:  49% 89/182 [17:58<18:19, 11.83s/it]\u001b[A\n",
            "Iteration:  49% 90/182 [18:09<18:10, 11.85s/it]\u001b[A\n",
            "Iteration:  50% 91/182 [18:21<18:01, 11.89s/it]\u001b[A\n",
            "Iteration:  51% 92/182 [18:33<17:45, 11.84s/it]\u001b[A\n",
            "Iteration:  51% 93/182 [18:45<17:36, 11.87s/it]\u001b[A\n",
            "Iteration:  52% 94/182 [18:57<17:25, 11.88s/it]\u001b[A\n",
            "Iteration:  52% 95/182 [19:09<17:09, 11.83s/it]\u001b[A\n",
            "Iteration:  53% 96/182 [19:20<16:54, 11.79s/it]\u001b[A\n",
            "Iteration:  53% 97/182 [19:32<16:42, 11.79s/it]\u001b[A\n",
            "Iteration:  54% 98/182 [19:44<16:33, 11.83s/it]\u001b[A\n",
            "Iteration:  54% 99/182 [19:56<16:23, 11.85s/it]\u001b[A\n",
            "Iteration:  55% 100/182 [20:08<16:03, 11.75s/it]\u001b[A\n",
            "Iteration:  55% 101/182 [20:20<16:02, 11.88s/it]\u001b[A\n",
            "Iteration:  56% 102/182 [20:32<15:58, 11.99s/it]\u001b[A\n",
            "Iteration:  57% 103/182 [20:44<15:46, 11.98s/it]\u001b[A\n",
            "Iteration:  57% 104/182 [20:56<15:37, 12.02s/it]\u001b[A\n",
            "Iteration:  58% 105/182 [21:08<15:32, 12.12s/it]\u001b[A\n",
            "Iteration:  58% 106/182 [21:20<15:20, 12.12s/it]\u001b[A\n",
            "Iteration:  59% 107/182 [21:32<15:04, 12.06s/it]\u001b[A\n",
            "Iteration:  59% 108/182 [21:45<14:53, 12.08s/it]\u001b[A\n",
            "Iteration:  60% 109/182 [21:56<14:34, 11.98s/it]\u001b[A\n",
            "Iteration:  60% 110/182 [22:08<14:18, 11.93s/it]\u001b[A\n",
            "Iteration:  61% 111/182 [22:20<14:04, 11.89s/it]\u001b[A\n",
            "Iteration:  62% 112/182 [22:32<13:51, 11.87s/it]\u001b[A\n",
            "Iteration:  62% 113/182 [22:44<13:39, 11.88s/it]\u001b[A\n",
            "Iteration:  63% 114/182 [22:56<13:30, 11.92s/it]\u001b[A\n",
            "Iteration:  63% 115/182 [23:08<13:20, 11.95s/it]\u001b[A\n",
            "Iteration:  64% 116/182 [23:20<13:16, 12.06s/it]\u001b[A\n",
            "Iteration:  64% 117/182 [23:32<12:58, 11.98s/it]\u001b[A\n",
            "Iteration:  65% 118/182 [23:44<12:43, 11.93s/it]\u001b[A\n",
            "Iteration:  65% 119/182 [23:55<12:27, 11.87s/it]\u001b[A\n",
            "Iteration:  66% 120/182 [24:07<12:12, 11.81s/it]\u001b[A\n",
            "Iteration:  66% 121/182 [24:19<12:09, 11.96s/it]\u001b[A\n",
            "Iteration:  67% 122/182 [24:31<11:59, 11.99s/it]\u001b[A\n",
            "Iteration:  68% 123/182 [24:43<11:47, 11.99s/it]\u001b[A\n",
            "Iteration:  68% 124/182 [24:55<11:34, 11.97s/it]\u001b[A\n",
            "Iteration:  69% 125/182 [25:07<11:24, 12.01s/it]\u001b[A\n",
            "Iteration:  69% 126/182 [25:19<11:13, 12.02s/it]\u001b[A\n",
            "Iteration:  70% 127/182 [25:31<11:02, 12.04s/it]\u001b[A\n",
            "Iteration:  70% 128/182 [25:44<10:52, 12.08s/it]\u001b[A\n",
            "Iteration:  71% 129/182 [25:56<10:43, 12.15s/it]\u001b[A\n",
            "Iteration:  71% 130/182 [26:08<10:27, 12.07s/it]\u001b[A\n",
            "Iteration:  72% 131/182 [26:20<10:13, 12.03s/it]\u001b[A\n",
            "Iteration:  73% 132/182 [26:32<09:59, 12.00s/it]\u001b[A\n",
            "Iteration:  73% 133/182 [26:44<09:44, 11.94s/it]\u001b[A\n",
            "Iteration:  74% 134/182 [26:56<09:36, 12.01s/it]\u001b[A\n",
            "Iteration:  74% 135/182 [27:08<09:24, 12.01s/it]\u001b[A\n",
            "Iteration:  75% 136/182 [27:20<09:11, 12.00s/it]\u001b[A\n",
            "Iteration:  75% 137/182 [27:32<08:59, 11.98s/it]\u001b[A\n",
            "Iteration:  76% 138/182 [27:44<08:47, 11.98s/it]\u001b[A\n",
            "Iteration:  76% 139/182 [27:55<08:33, 11.93s/it]\u001b[A\n",
            "Iteration:  77% 140/182 [28:07<08:22, 11.96s/it]\u001b[A\n",
            "Iteration:  77% 141/182 [28:19<08:09, 11.95s/it]\u001b[A\n",
            "Iteration:  78% 142/182 [28:31<08:00, 12.00s/it]\u001b[A\n",
            "Iteration:  79% 143/182 [28:44<07:48, 12.02s/it]\u001b[A\n",
            "Iteration:  79% 144/182 [28:56<07:38, 12.06s/it]\u001b[A\n",
            "Iteration:  80% 145/182 [29:08<07:24, 12.00s/it]\u001b[A\n",
            "Iteration:  80% 146/182 [29:20<07:18, 12.19s/it]\u001b[A\n",
            "Iteration:  81% 147/182 [29:32<07:02, 12.08s/it]\u001b[A\n",
            "Iteration:  81% 148/182 [29:44<06:48, 12.00s/it]\u001b[A\n",
            "Iteration:  82% 149/182 [29:56<06:37, 12.05s/it]\u001b[A\n",
            "Iteration:  82% 150/182 [30:08<06:25, 12.05s/it]\u001b[A\n",
            "Iteration:  83% 151/182 [30:20<06:13, 12.05s/it]\u001b[A\n",
            "Iteration:  84% 152/182 [30:32<06:01, 12.05s/it]\u001b[A\n",
            "Iteration:  84% 153/182 [30:44<05:49, 12.05s/it]\u001b[A\n",
            "Iteration:  85% 154/182 [30:56<05:36, 12.03s/it]\u001b[A\n",
            "Iteration:  85% 155/182 [31:08<05:25, 12.06s/it]\u001b[A\n",
            "Iteration:  86% 156/182 [31:20<05:13, 12.07s/it]\u001b[A\n",
            "Iteration:  86% 157/182 [31:32<04:59, 11.98s/it]\u001b[A\n",
            "Iteration:  87% 158/182 [31:44<04:44, 11.87s/it]\u001b[A\n",
            "Iteration:  87% 159/182 [31:56<04:33, 11.89s/it]\u001b[A\n",
            "Iteration:  88% 160/182 [32:07<04:19, 11.81s/it]\u001b[A\n",
            "Iteration:  88% 161/182 [32:19<04:09, 11.90s/it]\u001b[A\n",
            "Iteration:  89% 162/182 [32:32<03:59, 12.00s/it]\u001b[A\n",
            "Iteration:  90% 163/182 [32:44<03:48, 12.02s/it]\u001b[A\n",
            "Iteration:  90% 164/182 [32:56<03:35, 11.97s/it]\u001b[A\n",
            "Iteration:  91% 165/182 [33:07<03:22, 11.92s/it]\u001b[A\n",
            "Iteration:  91% 166/182 [33:19<03:11, 11.97s/it]\u001b[A\n",
            "Iteration:  92% 167/182 [33:31<02:59, 11.94s/it]\u001b[A\n",
            "Iteration:  92% 168/182 [33:43<02:47, 11.94s/it]\u001b[A\n",
            "Iteration:  93% 169/182 [33:55<02:34, 11.90s/it]\u001b[A\n",
            "Iteration:  93% 170/182 [34:07<02:23, 11.97s/it]\u001b[A\n",
            "Iteration:  94% 171/182 [34:19<02:10, 11.90s/it]\u001b[A\n",
            "Iteration:  95% 172/182 [34:31<01:58, 11.90s/it]\u001b[A\n",
            "Iteration:  95% 173/182 [34:43<01:47, 11.92s/it]\u001b[A\n",
            "Iteration:  96% 174/182 [34:55<01:35, 11.89s/it]\u001b[A\n",
            "Iteration:  96% 175/182 [35:06<01:22, 11.85s/it]\u001b[A\n",
            "Iteration:  97% 176/182 [35:18<01:11, 11.84s/it]\u001b[A\n",
            "Iteration:  97% 177/182 [35:30<00:59, 11.89s/it]\u001b[A\n",
            "Iteration:  98% 178/182 [35:42<00:47, 11.87s/it]\u001b[A\n",
            "Iteration:  98% 179/182 [35:54<00:35, 11.90s/it]\u001b[A\n",
            "Iteration:  99% 180/182 [36:06<00:23, 11.87s/it]\u001b[A\n",
            "Iteration:  99% 181/182 [36:18<00:12, 12.08s/it]\u001b[A\n",
            "Iteration: 100% 182/182 [36:23<00:00, 12.00s/it]\n",
            "Epoch:  50% 2/4 [1:15:24<1:16:27, 2293.96s/it]\n",
            "Iteration:   0% 0/182 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   1% 1/182 [00:12<37:03, 12.29s/it]\u001b[A\n",
            "Iteration:   1% 2/182 [00:24<36:33, 12.18s/it]\u001b[A\n",
            "Iteration:   2% 3/182 [00:36<36:15, 12.15s/it]\u001b[A\n",
            "Iteration:   2% 4/182 [00:48<35:52, 12.09s/it]\u001b[A\n",
            "Iteration:   3% 5/182 [01:00<35:30, 12.04s/it]\u001b[A\n",
            "Iteration:   3% 6/182 [01:12<35:31, 12.11s/it]\u001b[A\n",
            "Iteration:   4% 7/182 [01:24<35:06, 12.04s/it]\u001b[A\n",
            "Iteration:   4% 8/182 [01:36<35:17, 12.17s/it]\u001b[A\n",
            "Iteration:   5% 9/182 [01:48<35:00, 12.14s/it]\u001b[A\n",
            "Iteration:   5% 10/182 [02:00<34:29, 12.03s/it]\u001b[A\n",
            "Iteration:   6% 11/182 [02:12<34:33, 12.12s/it]\u001b[A\n",
            "Iteration:   7% 12/182 [02:25<34:25, 12.15s/it]\u001b[A\n",
            "Iteration:   7% 13/182 [02:37<34:20, 12.19s/it]\u001b[A\n",
            "Iteration:   8% 14/182 [02:49<34:06, 12.18s/it]\u001b[A\n",
            "Iteration:   8% 15/182 [03:02<34:13, 12.29s/it]\u001b[A\n",
            "Iteration:   9% 16/182 [03:14<33:58, 12.28s/it]\u001b[A\n",
            "Iteration:   9% 17/182 [03:26<33:49, 12.30s/it]\u001b[A\n",
            "Iteration:  10% 18/182 [03:39<34:08, 12.49s/it]\u001b[A\n",
            "Iteration:  10% 19/182 [03:51<33:43, 12.41s/it]\u001b[A\n",
            "Iteration:  11% 20/182 [04:03<33:09, 12.28s/it]\u001b[A\n",
            "Iteration:  12% 21/182 [04:16<33:02, 12.31s/it]\u001b[A\n",
            "Iteration:  12% 22/182 [04:28<32:41, 12.26s/it]\u001b[A\n",
            "Iteration:  13% 23/182 [04:40<32:23, 12.22s/it]\u001b[A\n",
            "Iteration:  13% 24/182 [04:53<32:31, 12.35s/it]\u001b[A\n",
            "Iteration:  14% 25/182 [05:05<32:17, 12.34s/it]\u001b[A\n",
            "Iteration:  14% 26/182 [05:17<31:49, 12.24s/it]\u001b[A\n",
            "Iteration:  15% 27/182 [05:30<31:48, 12.31s/it]\u001b[A\n",
            "Iteration:  15% 28/182 [05:42<31:35, 12.31s/it]\u001b[A\n",
            "Iteration:  16% 29/182 [05:54<31:15, 12.26s/it]\u001b[A\n",
            "Iteration:  16% 30/182 [06:06<31:11, 12.31s/it]\u001b[A\n",
            "Iteration:  17% 31/182 [06:18<30:34, 12.15s/it]\u001b[A\n",
            "Iteration:  18% 32/182 [06:31<30:31, 12.21s/it]\u001b[A\n",
            "Iteration:  18% 33/182 [06:43<30:12, 12.16s/it]\u001b[A\n",
            "Iteration:  19% 34/182 [06:55<29:56, 12.14s/it]\u001b[A\n",
            "Iteration:  19% 35/182 [07:06<29:25, 12.01s/it]\u001b[A\n",
            "Iteration:  20% 36/182 [07:19<29:28, 12.11s/it]\u001b[A\n",
            "Iteration:  20% 37/182 [07:31<29:04, 12.03s/it]\u001b[A\n",
            "Iteration:  21% 38/182 [07:43<28:59, 12.08s/it]\u001b[A\n",
            "Iteration:  21% 39/182 [07:55<28:53, 12.12s/it]\u001b[A\n",
            "Iteration:  22% 40/182 [08:07<28:33, 12.07s/it]\u001b[A\n",
            "Iteration:  23% 41/182 [08:19<28:12, 12.00s/it]\u001b[A\n",
            "Iteration:  23% 42/182 [08:31<28:03, 12.02s/it]\u001b[A\n",
            "Iteration:  24% 43/182 [08:44<28:18, 12.22s/it]\u001b[A\n",
            "Iteration:  24% 44/182 [08:56<27:58, 12.16s/it]\u001b[A\n",
            "Iteration:  25% 45/182 [09:08<27:39, 12.11s/it]\u001b[A\n",
            "Iteration:  25% 46/182 [09:20<27:26, 12.10s/it]\u001b[A\n",
            "Iteration:  26% 47/182 [09:32<27:24, 12.18s/it]\u001b[A\n",
            "Iteration:  26% 48/182 [09:44<27:14, 12.20s/it]\u001b[A\n",
            "Iteration:  27% 49/182 [09:56<26:49, 12.10s/it]\u001b[A\n",
            "Iteration:  27% 50/182 [10:09<26:58, 12.26s/it]\u001b[A\n",
            "Iteration:  28% 51/182 [10:21<26:56, 12.34s/it]\u001b[A\n",
            "Iteration:  29% 52/182 [10:33<26:37, 12.29s/it]\u001b[A\n",
            "Iteration:  29% 53/182 [10:45<26:09, 12.17s/it]\u001b[A\n",
            "Iteration:  30% 54/182 [10:58<25:58, 12.18s/it]\u001b[A\n",
            "Iteration:  30% 55/182 [11:10<25:56, 12.26s/it]\u001b[A\n",
            "Iteration:  31% 56/182 [11:22<25:31, 12.16s/it]\u001b[A\n",
            "Iteration:  31% 57/182 [11:34<25:28, 12.23s/it]\u001b[A\n",
            "Iteration:  32% 58/182 [11:47<25:18, 12.24s/it]\u001b[A\n",
            "Iteration:  32% 59/182 [11:59<25:01, 12.21s/it]\u001b[A\n",
            "Iteration:  33% 60/182 [12:11<24:37, 12.11s/it]\u001b[A\n",
            "Iteration:  34% 61/182 [12:23<24:33, 12.18s/it]\u001b[A\n",
            "Iteration:  34% 62/182 [12:35<24:20, 12.17s/it]\u001b[A\n",
            "Iteration:  35% 63/182 [12:47<24:13, 12.21s/it]\u001b[A\n",
            "Iteration:  35% 64/182 [13:00<24:08, 12.27s/it]\u001b[A\n",
            "Iteration:  36% 65/182 [13:12<23:45, 12.18s/it]\u001b[A\n",
            "Iteration:  36% 66/182 [13:24<23:25, 12.12s/it]\u001b[A\n",
            "Iteration:  37% 67/182 [13:36<23:22, 12.19s/it]\u001b[A\n",
            "Iteration:  37% 68/182 [13:48<23:02, 12.12s/it]\u001b[A\n",
            "Iteration:  38% 69/182 [14:00<22:42, 12.06s/it]\u001b[A\n",
            "Iteration:  38% 70/182 [14:12<22:25, 12.02s/it]\u001b[A\n",
            "Iteration:  39% 71/182 [14:24<22:22, 12.09s/it]\u001b[A\n",
            "Iteration:  40% 72/182 [14:36<22:08, 12.08s/it]\u001b[A\n",
            "Iteration:  40% 73/182 [14:49<22:15, 12.25s/it]\u001b[A\n",
            "Iteration:  41% 74/182 [15:02<22:30, 12.50s/it]\u001b[A\n",
            "Iteration:  41% 75/182 [15:14<22:08, 12.42s/it]\u001b[A\n",
            "Iteration:  42% 76/182 [15:26<21:44, 12.30s/it]\u001b[A\n",
            "Iteration:  42% 77/182 [15:38<21:12, 12.12s/it]\u001b[A\n",
            "Iteration:  43% 78/182 [15:50<20:49, 12.01s/it]\u001b[A\n",
            "Iteration:  43% 79/182 [16:01<20:22, 11.87s/it]\u001b[A\n",
            "Iteration:  44% 80/182 [16:13<20:09, 11.86s/it]\u001b[A\n",
            "Iteration:  45% 81/182 [16:25<19:58, 11.86s/it]\u001b[A\n",
            "Iteration:  45% 82/182 [16:37<19:44, 11.84s/it]\u001b[A\n",
            "Iteration:  46% 83/182 [16:48<19:29, 11.81s/it]\u001b[A\n",
            "Iteration:  46% 84/182 [17:00<19:16, 11.81s/it]\u001b[A\n",
            "Iteration:  47% 85/182 [17:12<19:06, 11.82s/it]\u001b[A\n",
            "Iteration:  47% 86/182 [17:24<18:48, 11.76s/it]\u001b[A\n",
            "Iteration:  48% 87/182 [17:36<18:39, 11.78s/it]\u001b[A\n",
            "Iteration:  48% 88/182 [17:47<18:26, 11.78s/it]\u001b[A\n",
            "Iteration:  49% 89/182 [17:59<18:10, 11.72s/it]\u001b[A\n",
            "Iteration:  49% 90/182 [18:10<17:50, 11.64s/it]\u001b[A\n",
            "Iteration:  50% 91/182 [18:22<17:46, 11.72s/it]\u001b[A\n",
            "Iteration:  51% 92/182 [18:34<17:37, 11.75s/it]\u001b[A\n",
            "Iteration:  51% 93/182 [18:46<17:30, 11.81s/it]\u001b[A\n",
            "Iteration:  52% 94/182 [18:58<17:24, 11.87s/it]\u001b[A\n",
            "Iteration:  52% 95/182 [19:10<17:27, 12.04s/it]\u001b[A\n",
            "Iteration:  53% 96/182 [19:22<17:07, 11.95s/it]\u001b[A\n",
            "Iteration:  53% 97/182 [19:34<16:48, 11.86s/it]\u001b[A\n",
            "Iteration:  54% 98/182 [19:46<16:32, 11.82s/it]\u001b[A\n",
            "Iteration:  54% 99/182 [19:58<16:30, 11.93s/it]\u001b[A\n",
            "Iteration:  55% 100/182 [20:09<16:10, 11.84s/it]\u001b[A\n",
            "Iteration:  55% 101/182 [20:22<16:07, 11.94s/it]\u001b[A\n",
            "Iteration:  56% 102/182 [20:34<15:55, 11.95s/it]\u001b[A\n",
            "Iteration:  57% 103/182 [20:46<15:45, 11.97s/it]\u001b[A\n",
            "Iteration:  57% 104/182 [20:58<15:37, 12.02s/it]\u001b[A\n",
            "Iteration:  58% 105/182 [21:09<15:18, 11.93s/it]\u001b[A\n",
            "Iteration:  58% 106/182 [21:21<14:56, 11.79s/it]\u001b[A\n",
            "Iteration:  59% 107/182 [21:33<14:42, 11.76s/it]\u001b[A\n",
            "Iteration:  59% 108/182 [21:44<14:30, 11.76s/it]\u001b[A\n",
            "Iteration:  60% 109/182 [21:56<14:20, 11.79s/it]\u001b[A\n",
            "Iteration:  60% 110/182 [22:08<14:05, 11.74s/it]\u001b[A\n",
            "Iteration:  61% 111/182 [22:20<13:54, 11.75s/it]\u001b[A\n",
            "Iteration:  62% 112/182 [22:31<13:43, 11.77s/it]\u001b[A\n",
            "Iteration:  62% 113/182 [22:43<13:37, 11.85s/it]\u001b[A\n",
            "Iteration:  63% 114/182 [22:55<13:20, 11.77s/it]\u001b[A\n",
            "Iteration:  63% 115/182 [23:07<13:07, 11.76s/it]\u001b[A\n",
            "Iteration:  64% 116/182 [23:19<12:56, 11.77s/it]\u001b[A\n",
            "Iteration:  64% 117/182 [23:31<12:49, 11.84s/it]\u001b[A\n",
            "Iteration:  65% 118/182 [23:42<12:38, 11.85s/it]\u001b[A\n",
            "Iteration:  65% 119/182 [23:54<12:25, 11.84s/it]\u001b[A\n",
            "Iteration:  66% 120/182 [24:06<12:10, 11.78s/it]\u001b[A\n",
            "Iteration:  66% 121/182 [24:18<11:58, 11.78s/it]\u001b[A\n",
            "Iteration:  67% 122/182 [24:30<11:51, 11.85s/it]\u001b[A\n",
            "Iteration:  68% 123/182 [24:41<11:36, 11.81s/it]\u001b[A\n",
            "Iteration:  68% 124/182 [24:54<11:30, 11.91s/it]\u001b[A\n",
            "Iteration:  69% 125/182 [25:06<11:20, 11.94s/it]\u001b[A\n",
            "Iteration:  69% 126/182 [25:17<11:05, 11.89s/it]\u001b[A\n",
            "Iteration:  70% 127/182 [25:29<10:50, 11.83s/it]\u001b[A\n",
            "Iteration:  70% 128/182 [25:41<10:40, 11.86s/it]\u001b[A\n",
            "Iteration:  71% 129/182 [25:53<10:30, 11.89s/it]\u001b[A\n",
            "Iteration:  71% 130/182 [26:05<10:14, 11.82s/it]\u001b[A\n",
            "Iteration:  72% 131/182 [26:16<10:02, 11.80s/it]\u001b[A\n",
            "Iteration:  73% 132/182 [26:28<09:50, 11.82s/it]\u001b[A\n",
            "Iteration:  73% 133/182 [26:40<09:37, 11.79s/it]\u001b[A\n",
            "Iteration:  74% 134/182 [26:52<09:30, 11.89s/it]\u001b[A\n",
            "Iteration:  74% 135/182 [27:04<09:15, 11.82s/it]\u001b[A/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:224: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
            "04/01/2020 18:10:09 - INFO - transformers.configuration_utils -   Configuration saved in /content/drive/My Drive/Colab Notebooks/W266/L2Models1E-0416Batch/4Epoch/checkpoint-500/config.json\n",
            "04/01/2020 18:10:10 - INFO - transformers.modeling_utils -   Model weights saved in /content/drive/My Drive/Colab Notebooks/W266/L2Models1E-0416Batch/4Epoch/checkpoint-500/pytorch_model.bin\n",
            "04/01/2020 18:10:10 - INFO - __main__ -   Saving model checkpoint to /content/drive/My Drive/Colab Notebooks/W266/L2Models1E-0416Batch/4Epoch/checkpoint-500\n",
            "04/01/2020 18:10:15 - INFO - __main__ -   Saving optimizer and scheduler states to /content/drive/My Drive/Colab Notebooks/W266/L2Models1E-0416Batch/4Epoch/checkpoint-500\n",
            "\n",
            "Iteration:  75% 136/182 [27:21<10:19, 13.46s/it]\u001b[A\n",
            "Iteration:  75% 137/182 [27:33<09:48, 13.07s/it]\u001b[A\n",
            "Iteration:  76% 138/182 [27:46<09:26, 12.88s/it]\u001b[A\n",
            "Iteration:  76% 139/182 [27:57<09:00, 12.57s/it]\u001b[A\n",
            "Iteration:  77% 140/182 [28:09<08:38, 12.35s/it]\u001b[A\n",
            "Iteration:  77% 141/182 [28:21<08:19, 12.18s/it]\u001b[A\n",
            "Iteration:  78% 142/182 [28:33<08:01, 12.04s/it]\u001b[A\n",
            "Iteration:  79% 143/182 [28:45<07:46, 11.97s/it]\u001b[A\n",
            "Iteration:  79% 144/182 [28:56<07:32, 11.92s/it]\u001b[A\n",
            "Iteration:  80% 145/182 [29:08<07:16, 11.81s/it]\u001b[A\n",
            "Iteration:  80% 146/182 [29:20<07:05, 11.82s/it]\u001b[A\n",
            "Iteration:  81% 147/182 [29:32<06:53, 11.82s/it]\u001b[A\n",
            "Iteration:  81% 148/182 [29:43<06:42, 11.83s/it]\u001b[A\n",
            "Iteration:  82% 149/182 [29:55<06:30, 11.85s/it]\u001b[A\n",
            "Iteration:  82% 150/182 [30:07<06:16, 11.78s/it]\u001b[A\n",
            "Iteration:  83% 151/182 [30:19<06:04, 11.75s/it]\u001b[A\n",
            "Iteration:  84% 152/182 [30:30<05:51, 11.73s/it]\u001b[A\n",
            "Iteration:  84% 153/182 [30:42<05:41, 11.77s/it]\u001b[A\n",
            "Iteration:  85% 154/182 [30:55<05:35, 11.96s/it]\u001b[A\n",
            "Iteration:  85% 155/182 [31:07<05:23, 12.00s/it]\u001b[A\n",
            "Iteration:  86% 156/182 [31:18<05:09, 11.91s/it]\u001b[A\n",
            "Iteration:  86% 157/182 [31:30<04:57, 11.90s/it]\u001b[A\n",
            "Iteration:  87% 158/182 [31:42<04:46, 11.93s/it]\u001b[A\n",
            "Iteration:  87% 159/182 [31:54<04:34, 11.93s/it]\u001b[A\n",
            "Iteration:  88% 160/182 [32:06<04:22, 11.93s/it]\u001b[A\n",
            "Iteration:  88% 161/182 [32:18<04:09, 11.88s/it]\u001b[A\n",
            "Iteration:  89% 162/182 [32:30<03:57, 11.89s/it]\u001b[A\n",
            "Iteration:  90% 163/182 [32:42<03:45, 11.85s/it]\u001b[A\n",
            "Iteration:  90% 164/182 [32:53<03:33, 11.86s/it]\u001b[A\n",
            "Iteration:  91% 165/182 [33:05<03:20, 11.77s/it]\u001b[A\n",
            "Iteration:  91% 166/182 [33:17<03:07, 11.74s/it]\u001b[A\n",
            "Iteration:  92% 167/182 [33:28<02:55, 11.72s/it]\u001b[A\n",
            "Iteration:  92% 168/182 [33:40<02:44, 11.73s/it]\u001b[A\n",
            "Iteration:  93% 169/182 [33:52<02:32, 11.73s/it]\u001b[A\n",
            "Iteration:  93% 170/182 [34:03<02:19, 11.66s/it]\u001b[A\n",
            "Iteration:  94% 171/182 [34:15<02:09, 11.74s/it]\u001b[A\n",
            "Iteration:  95% 172/182 [34:27<01:57, 11.70s/it]\u001b[A\n",
            "Iteration:  95% 173/182 [34:38<01:45, 11.68s/it]\u001b[A\n",
            "Iteration:  96% 174/182 [34:50<01:33, 11.68s/it]\u001b[A\n",
            "Iteration:  96% 175/182 [35:02<01:22, 11.76s/it]\u001b[A\n",
            "Iteration:  97% 176/182 [35:14<01:10, 11.80s/it]\u001b[A\n",
            "Iteration:  97% 177/182 [35:26<00:59, 11.90s/it]\u001b[A\n",
            "Iteration:  98% 178/182 [35:38<00:47, 11.84s/it]\u001b[A\n",
            "Iteration:  98% 179/182 [35:50<00:35, 11.83s/it]\u001b[A\n",
            "Iteration:  99% 180/182 [36:02<00:23, 11.88s/it]\u001b[A\n",
            "Iteration:  99% 181/182 [36:14<00:11, 11.90s/it]\u001b[A\n",
            "Iteration: 100% 182/182 [36:18<00:00, 11.97s/it]\n",
            "Epoch:  75% 3/4 [1:51:43<37:39, 2259.37s/it]  \n",
            "Iteration:   0% 0/182 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   1% 1/182 [00:11<36:03, 11.95s/it]\u001b[A\n",
            "Iteration:   1% 2/182 [00:23<35:50, 11.95s/it]\u001b[A\n",
            "Iteration:   2% 3/182 [00:35<35:38, 11.95s/it]\u001b[A\n",
            "Iteration:   2% 4/182 [00:47<35:14, 11.88s/it]\u001b[A\n",
            "Iteration:   3% 5/182 [00:59<34:44, 11.78s/it]\u001b[A\n",
            "Iteration:   3% 6/182 [01:11<34:54, 11.90s/it]\u001b[A\n",
            "Iteration:   4% 7/182 [01:23<34:56, 11.98s/it]\u001b[A\n",
            "Iteration:   4% 8/182 [01:35<34:47, 12.00s/it]\u001b[A\n",
            "Iteration:   5% 9/182 [01:47<34:43, 12.04s/it]\u001b[A\n",
            "Iteration:   5% 10/182 [01:59<34:16, 11.95s/it]\u001b[A\n",
            "Iteration:   6% 11/182 [02:11<33:58, 11.92s/it]\u001b[A\n",
            "Iteration:   7% 12/182 [02:23<33:39, 11.88s/it]\u001b[A\n",
            "Iteration:   7% 13/182 [02:35<33:38, 11.94s/it]\u001b[A\n",
            "Iteration:   8% 14/182 [02:46<33:21, 11.92s/it]\u001b[A\n",
            "Iteration:   8% 15/182 [02:58<33:15, 11.95s/it]\u001b[A\n",
            "Iteration:   9% 16/182 [03:10<32:56, 11.90s/it]\u001b[A\n",
            "Iteration:   9% 17/182 [03:22<32:39, 11.88s/it]\u001b[A\n",
            "Iteration:  10% 18/182 [03:34<32:13, 11.79s/it]\u001b[A\n",
            "Iteration:  10% 19/182 [03:45<31:46, 11.70s/it]\u001b[A\n",
            "Iteration:  11% 20/182 [03:57<31:34, 11.70s/it]\u001b[A\n",
            "Iteration:  12% 21/182 [04:09<31:22, 11.69s/it]\u001b[A\n",
            "Iteration:  12% 22/182 [04:20<31:05, 11.66s/it]\u001b[A\n",
            "Iteration:  13% 23/182 [04:32<30:49, 11.63s/it]\u001b[A\n",
            "Iteration:  13% 24/182 [04:43<30:43, 11.67s/it]\u001b[A\n",
            "Iteration:  14% 25/182 [04:55<30:42, 11.73s/it]\u001b[A\n",
            "Iteration:  14% 26/182 [05:07<30:45, 11.83s/it]\u001b[A\n",
            "Iteration:  15% 27/182 [05:19<30:18, 11.73s/it]\u001b[A\n",
            "Iteration:  15% 28/182 [05:31<30:25, 11.85s/it]\u001b[A\n",
            "Iteration:  16% 29/182 [05:43<30:04, 11.79s/it]\u001b[A\n",
            "Iteration:  16% 30/182 [05:55<30:01, 11.85s/it]\u001b[A\n",
            "Iteration:  17% 31/182 [06:07<29:53, 11.88s/it]\u001b[A\n",
            "Iteration:  18% 32/182 [06:18<29:38, 11.85s/it]\u001b[A\n",
            "Iteration:  18% 33/182 [06:30<29:33, 11.90s/it]\u001b[A\n",
            "Iteration:  19% 34/182 [06:43<29:31, 11.97s/it]\u001b[A\n",
            "Iteration:  19% 35/182 [06:55<29:24, 12.01s/it]\u001b[A\n",
            "Iteration:  20% 36/182 [07:06<28:55, 11.88s/it]\u001b[A\n",
            "Iteration:  20% 37/182 [07:18<28:32, 11.81s/it]\u001b[A\n",
            "Iteration:  21% 38/182 [07:30<28:18, 11.79s/it]\u001b[A\n",
            "Iteration:  21% 39/182 [07:41<27:58, 11.74s/it]\u001b[A\n",
            "Iteration:  22% 40/182 [07:53<27:47, 11.75s/it]\u001b[A\n",
            "Iteration:  23% 41/182 [08:05<27:51, 11.86s/it]\u001b[A\n",
            "Iteration:  23% 42/182 [08:17<27:31, 11.80s/it]\u001b[A\n",
            "Iteration:  24% 43/182 [08:28<27:10, 11.73s/it]\u001b[A\n",
            "Iteration:  24% 44/182 [08:40<27:14, 11.85s/it]\u001b[A\n",
            "Iteration:  25% 45/182 [08:53<27:15, 11.94s/it]\u001b[A\n",
            "Iteration:  25% 46/182 [09:04<26:56, 11.88s/it]\u001b[A\n",
            "Iteration:  26% 47/182 [09:16<26:46, 11.90s/it]\u001b[A\n",
            "Iteration:  26% 48/182 [09:28<26:33, 11.89s/it]\u001b[A\n",
            "Iteration:  27% 49/182 [09:40<26:19, 11.88s/it]\u001b[A\n",
            "Iteration:  27% 50/182 [09:52<25:54, 11.78s/it]\u001b[A\n",
            "Iteration:  28% 51/182 [10:03<25:44, 11.79s/it]\u001b[A\n",
            "Iteration:  29% 52/182 [10:16<25:45, 11.89s/it]\u001b[A\n",
            "Iteration:  29% 53/182 [10:27<25:17, 11.76s/it]\u001b[A\n",
            "Iteration:  30% 54/182 [10:39<25:07, 11.77s/it]\u001b[A\n",
            "Iteration:  30% 55/182 [10:51<24:56, 11.78s/it]\u001b[A\n",
            "Iteration:  31% 56/182 [11:02<24:42, 11.76s/it]\u001b[A\n",
            "Iteration:  31% 57/182 [11:14<24:24, 11.72s/it]\u001b[A\n",
            "Iteration:  32% 58/182 [11:26<24:15, 11.74s/it]\u001b[A\n",
            "Iteration:  32% 59/182 [11:37<24:02, 11.73s/it]\u001b[A\n",
            "Iteration:  33% 60/182 [11:50<24:15, 11.93s/it]\u001b[A\n",
            "Iteration:  34% 61/182 [12:02<24:00, 11.91s/it]\u001b[A\n",
            "Iteration:  34% 62/182 [12:14<23:48, 11.90s/it]\u001b[A\n",
            "Iteration:  35% 63/182 [12:25<23:31, 11.86s/it]\u001b[A\n",
            "Iteration:  35% 64/182 [12:38<23:33, 11.98s/it]\u001b[A\n",
            "Iteration:  36% 65/182 [12:49<23:14, 11.92s/it]\u001b[A\n",
            "Iteration:  36% 66/182 [13:01<22:48, 11.80s/it]\u001b[A\n",
            "Iteration:  37% 67/182 [13:13<22:33, 11.77s/it]\u001b[A\n",
            "Iteration:  37% 68/182 [13:25<22:29, 11.84s/it]\u001b[A\n",
            "Iteration:  38% 69/182 [13:36<22:18, 11.84s/it]\u001b[A\n",
            "Iteration:  38% 70/182 [13:48<22:01, 11.80s/it]\u001b[A\n",
            "Iteration:  39% 71/182 [14:00<21:45, 11.76s/it]\u001b[A\n",
            "Iteration:  40% 72/182 [14:12<21:33, 11.76s/it]\u001b[A\n",
            "Iteration:  40% 73/182 [14:23<21:16, 11.71s/it]\u001b[A\n",
            "Iteration:  41% 74/182 [14:35<21:07, 11.74s/it]\u001b[A\n",
            "Iteration:  41% 75/182 [14:47<20:59, 11.77s/it]\u001b[A\n",
            "Iteration:  42% 76/182 [14:59<20:54, 11.83s/it]\u001b[A\n",
            "Iteration:  42% 77/182 [15:11<20:46, 11.87s/it]\u001b[A\n",
            "Iteration:  43% 78/182 [15:23<20:40, 11.92s/it]\u001b[A\n",
            "Iteration:  43% 79/182 [15:35<20:27, 11.92s/it]\u001b[A\n",
            "Iteration:  44% 80/182 [15:46<20:11, 11.88s/it]\u001b[A\n",
            "Iteration:  45% 81/182 [15:59<20:06, 11.95s/it]\u001b[A\n",
            "Iteration:  45% 82/182 [16:11<19:56, 11.96s/it]\u001b[A\n",
            "Iteration:  46% 83/182 [16:23<19:45, 11.98s/it]\u001b[A\n",
            "Iteration:  46% 84/182 [16:35<19:35, 11.99s/it]\u001b[A\n",
            "Iteration:  47% 85/182 [16:46<19:14, 11.90s/it]\u001b[A\n",
            "Iteration:  47% 86/182 [16:58<19:02, 11.90s/it]\u001b[A\n",
            "Iteration:  48% 87/182 [17:10<18:54, 11.94s/it]\u001b[A\n",
            "Iteration:  48% 88/182 [17:22<18:38, 11.89s/it]\u001b[A\n",
            "Iteration:  49% 89/182 [17:34<18:26, 11.90s/it]\u001b[A\n",
            "Iteration:  49% 90/182 [17:46<18:14, 11.90s/it]\u001b[A\n",
            "Iteration:  50% 91/182 [17:58<17:57, 11.84s/it]\u001b[A\n",
            "Iteration:  51% 92/182 [18:09<17:38, 11.77s/it]\u001b[A\n",
            "Iteration:  51% 93/182 [18:21<17:25, 11.74s/it]\u001b[A\n",
            "Iteration:  52% 94/182 [18:32<17:08, 11.68s/it]\u001b[A\n",
            "Iteration:  52% 95/182 [18:44<16:58, 11.71s/it]\u001b[A\n",
            "Iteration:  53% 96/182 [18:56<16:47, 11.71s/it]\u001b[A\n",
            "Iteration:  53% 97/182 [19:08<16:35, 11.71s/it]\u001b[A\n",
            "Iteration:  54% 98/182 [19:19<16:15, 11.61s/it]\u001b[A\n",
            "Iteration:  54% 99/182 [19:30<16:02, 11.60s/it]\u001b[A\n",
            "Iteration:  55% 100/182 [19:42<15:51, 11.61s/it]\u001b[A\n",
            "Iteration:  55% 101/182 [19:54<15:57, 11.82s/it]\u001b[A\n",
            "Iteration:  56% 102/182 [20:06<15:42, 11.78s/it]\u001b[A\n",
            "Iteration:  57% 103/182 [20:18<15:33, 11.81s/it]\u001b[A\n",
            "Iteration:  57% 104/182 [20:31<15:41, 12.07s/it]\u001b[A\n",
            "Iteration:  58% 105/182 [20:43<15:37, 12.17s/it]\u001b[A\n",
            "Iteration:  58% 106/182 [20:56<15:34, 12.30s/it]\u001b[A\n",
            "Iteration:  59% 107/182 [21:08<15:29, 12.39s/it]\u001b[A\n",
            "Iteration:  59% 108/182 [21:21<15:16, 12.39s/it]\u001b[A\n",
            "Iteration:  60% 109/182 [21:33<15:08, 12.45s/it]\u001b[A\n",
            "Iteration:  60% 110/182 [21:46<14:51, 12.38s/it]\u001b[A\n",
            "Iteration:  61% 111/182 [21:58<14:42, 12.43s/it]\u001b[A\n",
            "Iteration:  62% 112/182 [22:10<14:22, 12.31s/it]\u001b[A\n",
            "Iteration:  62% 113/182 [22:22<14:02, 12.21s/it]\u001b[A\n",
            "Iteration:  63% 114/182 [22:34<13:45, 12.15s/it]\u001b[A\n",
            "Iteration:  63% 115/182 [22:46<13:33, 12.14s/it]\u001b[A\n",
            "Iteration:  64% 116/182 [22:58<13:22, 12.17s/it]\u001b[A\n",
            "Iteration:  64% 117/182 [23:11<13:19, 12.30s/it]\u001b[A\n",
            "Iteration:  65% 118/182 [23:24<13:12, 12.38s/it]\u001b[A\n",
            "Iteration:  65% 119/182 [23:36<12:58, 12.35s/it]\u001b[A\n",
            "Iteration:  66% 120/182 [23:48<12:44, 12.32s/it]\u001b[A\n",
            "Iteration:  66% 121/182 [24:01<12:35, 12.38s/it]\u001b[A\n",
            "Iteration:  67% 122/182 [24:14<12:32, 12.55s/it]\u001b[A\n",
            "Iteration:  68% 123/182 [24:27<12:30, 12.71s/it]\u001b[A\n",
            "Iteration:  68% 124/182 [24:39<12:15, 12.67s/it]\u001b[A\n",
            "Iteration:  69% 125/182 [24:52<11:57, 12.58s/it]\u001b[A\n",
            "Iteration:  69% 126/182 [25:04<11:35, 12.42s/it]\u001b[A\n",
            "Iteration:  70% 127/182 [25:16<11:24, 12.45s/it]\u001b[A\n",
            "Iteration:  70% 128/182 [25:29<11:16, 12.54s/it]\u001b[A\n",
            "Iteration:  71% 129/182 [25:42<11:11, 12.67s/it]\u001b[A\n",
            "Iteration:  71% 130/182 [25:55<11:01, 12.71s/it]\u001b[A\n",
            "Iteration:  72% 131/182 [26:07<10:46, 12.68s/it]\u001b[A\n",
            "Iteration:  73% 132/182 [26:20<10:32, 12.65s/it]\u001b[A\n",
            "Iteration:  73% 133/182 [26:32<10:13, 12.52s/it]\u001b[A\n",
            "Iteration:  74% 134/182 [26:45<10:01, 12.53s/it]\u001b[A\n",
            "Iteration:  74% 135/182 [26:57<09:46, 12.49s/it]\u001b[A\n",
            "Iteration:  75% 136/182 [27:09<09:32, 12.45s/it]\u001b[A\n",
            "Iteration:  75% 137/182 [27:21<09:14, 12.33s/it]\u001b[A\n",
            "Iteration:  76% 138/182 [27:34<09:03, 12.35s/it]\u001b[A\n",
            "Iteration:  76% 139/182 [27:46<08:46, 12.23s/it]\u001b[A\n",
            "Iteration:  77% 140/182 [27:58<08:34, 12.24s/it]\u001b[A\n",
            "Iteration:  77% 141/182 [28:11<08:24, 12.30s/it]\u001b[A\n",
            "Iteration:  78% 142/182 [28:23<08:09, 12.25s/it]\u001b[A\n",
            "Iteration:  79% 143/182 [28:34<07:48, 12.01s/it]\u001b[A\n",
            "Iteration:  79% 144/182 [28:46<07:32, 11.90s/it]\u001b[A\n",
            "Iteration:  80% 145/182 [28:58<07:19, 11.87s/it]\u001b[A\n",
            "Iteration:  80% 146/182 [29:10<07:11, 11.99s/it]\u001b[A\n",
            "Iteration:  81% 147/182 [29:22<06:59, 11.98s/it]\u001b[A\n",
            "Iteration:  81% 148/182 [29:34<06:48, 12.00s/it]\u001b[A\n",
            "Iteration:  82% 149/182 [29:45<06:31, 11.87s/it]\u001b[A\n",
            "Iteration:  82% 150/182 [29:57<06:15, 11.74s/it]\u001b[A\n",
            "Iteration:  83% 151/182 [30:09<06:03, 11.73s/it]\u001b[A\n",
            "Iteration:  84% 152/182 [30:20<05:52, 11.75s/it]\u001b[A\n",
            "Iteration:  84% 153/182 [30:32<05:40, 11.73s/it]\u001b[A\n",
            "Iteration:  85% 154/182 [30:44<05:30, 11.79s/it]\u001b[A\n",
            "Iteration:  85% 155/182 [30:56<05:20, 11.87s/it]\u001b[A\n",
            "Iteration:  86% 156/182 [31:08<05:09, 11.90s/it]\u001b[A\n",
            "Iteration:  86% 157/182 [31:20<04:55, 11.82s/it]\u001b[A\n",
            "Iteration:  87% 158/182 [31:31<04:42, 11.76s/it]\u001b[A\n",
            "Iteration:  87% 159/182 [31:43<04:31, 11.82s/it]\u001b[A\n",
            "Iteration:  88% 160/182 [31:55<04:19, 11.79s/it]\u001b[A\n",
            "Iteration:  88% 161/182 [32:07<04:08, 11.81s/it]\u001b[A\n",
            "Iteration:  89% 162/182 [32:19<03:56, 11.82s/it]\u001b[A\n",
            "Iteration:  90% 163/182 [32:30<03:42, 11.73s/it]\u001b[A\n",
            "Iteration:  90% 164/182 [32:42<03:32, 11.83s/it]\u001b[A\n",
            "Iteration:  91% 165/182 [32:54<03:19, 11.76s/it]\u001b[A\n",
            "Iteration:  91% 166/182 [33:06<03:08, 11.78s/it]\u001b[A\n",
            "Iteration:  92% 167/182 [33:17<02:55, 11.69s/it]\u001b[A\n",
            "Iteration:  92% 168/182 [33:29<02:43, 11.68s/it]\u001b[A\n",
            "Iteration:  93% 169/182 [33:41<02:33, 11.79s/it]\u001b[A\n",
            "Iteration:  93% 170/182 [33:53<02:21, 11.79s/it]\u001b[A\n",
            "Iteration:  94% 171/182 [34:04<02:09, 11.74s/it]\u001b[A\n",
            "Iteration:  95% 172/182 [34:16<01:57, 11.76s/it]\u001b[A\n",
            "Iteration:  95% 173/182 [34:28<01:45, 11.71s/it]\u001b[A\n",
            "Iteration:  96% 174/182 [34:40<01:34, 11.76s/it]\u001b[A\n",
            "Iteration:  96% 175/182 [34:51<01:22, 11.79s/it]\u001b[A\n",
            "Iteration:  97% 176/182 [35:03<01:10, 11.73s/it]\u001b[A\n",
            "Iteration:  97% 177/182 [35:15<00:58, 11.72s/it]\u001b[A\n",
            "Iteration:  98% 178/182 [35:26<00:46, 11.72s/it]\u001b[A\n",
            "Iteration:  98% 179/182 [35:38<00:35, 11.72s/it]\u001b[A\n",
            "Iteration:  99% 180/182 [35:50<00:23, 11.73s/it]\u001b[A\n",
            "Iteration:  99% 181/182 [36:02<00:11, 11.86s/it]\u001b[A\n",
            "Iteration: 100% 182/182 [36:07<00:00, 11.91s/it]\n",
            "Epoch: 100% 4/4 [2:27:51<00:00, 2217.80s/it]\n",
            "04/01/2020 18:55:20 - INFO - __main__ -    global_step = 728, average loss = 1.7414712724122372\n",
            "04/01/2020 18:55:20 - INFO - __main__ -   Saving model checkpoint to /content/drive/My Drive/Colab Notebooks/W266/L2Models1E-0416Batch/4Epoch\n",
            "04/01/2020 18:55:20 - INFO - transformers.configuration_utils -   Configuration saved in /content/drive/My Drive/Colab Notebooks/W266/L2Models1E-0416Batch/4Epoch/config.json\n",
            "04/01/2020 18:55:21 - INFO - transformers.modeling_utils -   Model weights saved in /content/drive/My Drive/Colab Notebooks/W266/L2Models1E-0416Batch/4Epoch/pytorch_model.bin\n",
            "04/01/2020 18:55:21 - INFO - transformers.configuration_utils -   loading configuration file /content/drive/My Drive/Colab Notebooks/W266/L2Models1E-0416Batch/4Epoch/config.json\n",
            "04/01/2020 18:55:21 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
            "  \"_num_labels\": 2,\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": null,\n",
            "  \"decoder_start_token_id\": null,\n",
            "  \"do_sample\": false,\n",
            "  \"early_stopping\": false,\n",
            "  \"eos_token_id\": null,\n",
            "  \"eos_token_ids\": null,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"is_encoder_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"min_length\": 0,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"no_repeat_ngram_size\": 0,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": null,\n",
            "  \"prefix\": null,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"task_specific_params\": null,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "04/01/2020 18:55:21 - INFO - transformers.modeling_utils -   loading weights file /content/drive/My Drive/Colab Notebooks/W266/L2Models1E-0416Batch/4Epoch/pytorch_model.bin\n",
            "04/01/2020 18:55:24 - INFO - transformers.tokenization_utils -   Model name '/content/drive/My Drive/Colab Notebooks/W266/L2Models1E-0416Batch/4Epoch' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming '/content/drive/My Drive/Colab Notebooks/W266/L2Models1E-0416Batch/4Epoch' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
            "04/01/2020 18:55:24 - INFO - transformers.tokenization_utils -   Didn't find file /content/drive/My Drive/Colab Notebooks/W266/L2Models1E-0416Batch/4Epoch/added_tokens.json. We won't load it.\n",
            "04/01/2020 18:55:24 - INFO - transformers.tokenization_utils -   loading file /content/drive/My Drive/Colab Notebooks/W266/L2Models1E-0416Batch/4Epoch/vocab.txt\n",
            "04/01/2020 18:55:24 - INFO - transformers.tokenization_utils -   loading file None\n",
            "04/01/2020 18:55:24 - INFO - transformers.tokenization_utils -   loading file /content/drive/My Drive/Colab Notebooks/W266/L2Models1E-0416Batch/4Epoch/special_tokens_map.json\n",
            "04/01/2020 18:55:24 - INFO - transformers.tokenization_utils -   loading file /content/drive/My Drive/Colab Notebooks/W266/L2Models1E-0416Batch/4Epoch/tokenizer_config.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5j_f6DwWpKX",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}