{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline CNN Model Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import collections\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
    "from sklearn.utils import shuffle\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import *\n",
    "import pickle\n",
    "import torch.utils.data\n",
    "import torch.optim as optim\n",
    "from model import ConvNet\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Processing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseTrainData(topicLabels, df):\n",
    "    data = {}\n",
    "    labels = {}\n",
    "    \n",
    "    for dataType in ['train']:\n",
    "        data[dataType] = {}\n",
    "        labels[dataType] = {}\n",
    "        \n",
    "        for topic in topicLabels:\n",
    "            data[dataType][topic] = []\n",
    "            labels[dataType][topic] = []\n",
    "            \n",
    "            for idx, sentence in df.iterrows(): # iterates through each sentence in df we passed\n",
    "                if sentence.category == topic:\n",
    "                    data[dataType][topic].append(sentence.text)\n",
    "                    labels[dataType][topic].append(topicLabels[sentence.category]) # assigns it the value in our dict of topicLabels based on each category\n",
    "            \n",
    "            assert len(data[dataType][topic]) == len(labels[dataType][topic]), \\\n",
    "                    \"{}/{} data size does not match labels size\".format(data_type, topic)\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage, we have in read in the raw training and testing data and formatted it properly, and now we are going to shuffle the records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareTrainData(data, labels):\n",
    "    \"\"\"Prepare training set from L3 Data\"\"\"\n",
    "    \n",
    "    # Combine pro and anti sentences and labels\n",
    "    dataTrain = data['train']['pro-immigration'] + data['train']['anti-immigration'] + data['train']['pro-guns'] + data['train']['anti-guns'] + data['train']['pro-medicare'] + data['train']['oppose-medicare']\n",
    "    labelsTrain = labels['train']['pro-immigration'] + labels['train']['anti-immigration'] + labels['train']['pro-guns'] + labels['train']['anti-guns'] + labels['train']['pro-medicare'] + labels['train']['oppose-medicare']\n",
    "    \n",
    "    # Shuffle sentences and the corresponding labels within the training data\n",
    "    dataTrain, labelsTrain = shuffle(dataTrain, labelsTrain)\n",
    "    \n",
    "    # Return shuffled training data and training labels\n",
    "    return dataTrain, labelsTrain\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareTestData(candidates):\n",
    "    testDict = {}\n",
    "    for candidate in candidates:\n",
    "        df = pd.read_csv('./data/' + candidate + '_cleaned.csv')\n",
    "        convertToList = df.text.to_list()\n",
    "        wordsTest = [sentenceToWords(sentence) for sentence in convertToList]\n",
    "        testDict[candidate] = wordsTest\n",
    "    return testDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to tokenize our input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentenceToWords(sentence):\n",
    "    nltk.download(\"stopwords\", quiet = True)\n",
    "    # stemmer = PorterStemmer()\n",
    "    \n",
    "    sentence = re.sub(r\"[^a-zA-Z0-9]\", \" \", sentence.lower()) # Convert text to lower case\n",
    "    words = sentence.split() # Split string into words\n",
    "    words = [w for w in words if w not in stopwords.words(\"english\")] # Remove stopwords\n",
    "    # words = [PorterStemmer().stem(w) for w in words] # stem\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will apply the above method to all of our data and cache the results as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cacheDir = os.path.join(\"../cache\", \"cnn_analysis\")  # where to store cache files\n",
    "os.makedirs(cacheDir, exist_ok=True)  # ensure cache directory exists\n",
    "\n",
    "def preprocessData(dataTrain, labelsTrain, cacheDir = cacheDir, cacheFile = \"preprocessedData.pkl\"):\n",
    "    \"\"\"Convert each review to words; read from cache if available.\"\"\"\n",
    "    \n",
    "    # If cache_file is not None, try to read from it first\n",
    "    cacheData = None\n",
    "    if cacheFile is not None:\n",
    "        try:\n",
    "            pass\n",
    "        except:\n",
    "            pass  # unable to read from cache, but that's okay\n",
    "        \n",
    "      # If cache is missing, then do the heavy lifting\n",
    "    if cacheData is None:\n",
    "        # Preprocess training and test data to obtain words for each review\n",
    "        # words_train = list(map(review_to_words, data_train))\n",
    "        # words_test = list(map(review_to_words, data_test))\n",
    "        wordsTrain = [sentenceToWords(sentence) for sentence in dataTrain]\n",
    "        \n",
    "        # Write to cache file for future runs\n",
    "        if cacheFile is not None:\n",
    "            cacheData = dict(wordsTrain=wordsTrain, labelsTrain=labelsTrain)\n",
    "            \n",
    "            with open(os.path.join(cacheDir, cacheFile), \"wb\") as f:\n",
    "                pickle.dump(cacheData, f)\n",
    "            print(\"Wrote preprocessed data to cache file:\", cacheFile)\n",
    "        \n",
    "    else:\n",
    "        # Unpack data loaded from cache file\n",
    "        wordsTrain, labelsTrain = (cacheData['wordsTrain'], cacheData['labelsTrain'])\n",
    "        \n",
    "    return wordsTrain, labelsTrain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will construct a feature representation that represents each word as an integer and include the words that appear most frequently.  We will combine all the infrequent words into another category by itself.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildDict(data, vocabSize = 50000):\n",
    "    \"\"\"Construct and return a dictionary mapping each of the most frequently appearing words to a unique integer.\"\"\"\n",
    "    # Determine how often each word appears in `data`. Note that `data` is a list of sentences and that a\n",
    "    # sentence is a list of words.\n",
    "    \n",
    "    # A dict storing the words that appear in the reviews along with how often they occur\n",
    "    wordCount = {}\n",
    "    for sentence in data:\n",
    "        for word in sentence:\n",
    "            wordCount[word] = wordCount[word] + 1 if word in wordCount else 1\n",
    "            \n",
    "    # Sort the words found in `data` so that sorted_words[0] is the most frequently appearing word and\n",
    "    # sorted_words[-1] is the least frequently appearing word. \n",
    "    wordCountSorted = sorted(wordCount.items(), key=(lambda item: item[1]), reverse=True)\n",
    "    sortedWords = [item[0] for item in wordCountSorted]\n",
    "    \n",
    "    # This is what we are building, a dictionary that translates words into integers\n",
    "    wordDict = {}\n",
    "    for idx, word in enumerate(sortedWords[:vocabSize - 2]): # The -2 is so that we save room for the 'no word'\n",
    "        wordDict[word] = idx + 2\n",
    "    return wordDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have our word dictionary, so let's convert our sentences to integer sequence representation and pad our results to a fixed length.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertAndPad(wordDict, sentence, pad = 500):\n",
    "    NOWORD = 0 # We will use 0 to represent the 'no word' category\n",
    "    INFREQ = 1  # and we use 1 to represent the infrequent words, i.e., words not appearing in word_dict\n",
    "    \n",
    "    workingSentence = [NOWORD] * pad\n",
    "    \n",
    "    for wordIdx, word in enumerate(sentence[:pad]):\n",
    "        if word in wordDict:\n",
    "            workingSentence[wordIdx] = wordDict[word]\n",
    "        else:\n",
    "            workingSentence[wordIdx] = INFREQ\n",
    "        \n",
    "    return workingSentence, min(len(sentence), pad)\n",
    "\n",
    "def convertAndPadData(wordDict, data, pad = 500):\n",
    "    result = []\n",
    "    lengths = []\n",
    "    \n",
    "    for sentence in data:\n",
    "        converted, leng = convertAndPad(wordDict, sentence, pad)\n",
    "        result.append(converted)\n",
    "        lengths.append(leng)\n",
    "    \n",
    "    return np.array(result), np.array(lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build and Train the PyTorch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, trainLoader, epochs, optimizer, criterion, device):\n",
    "    total_step = len(trainLoader)\n",
    "    for epoch in range(epochs):\n",
    "        for idx, (data, labels) in enumerate(trainLoader):\n",
    "            data = data.to(device)\n",
    "            labels = data.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if (id+1) % 100 == 0:\n",
    "                print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                       .format(epoch+1, epochs, id+1, total_step, loss.item()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy the Model for Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the Model for Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Function for Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Immigration articles: train = 900 pro / 385 anti\n",
      "Immigration articles: train = 759 pro / 745 anti\n",
      "Immigration articles: train = 673 pro / 639 anti\n",
      "Counter({0: 900, 2: 759, 3: 745, 4: 673, 5: 639, 1: 385})\n",
      "Sentences (combined): train = 4101\n",
      "Suderman describes the inference he tries to draw from Shumlin’s cold feet as “the strongest argument against Mr. Sanders’s single-player plan.” As a defender of Sanders’s plan, I hope he’s right.\n",
      "['fifty', 'four', 'years', 'ago', 'united', 'states', 'took', 'important', 'step', 'towards', 'universal', 'health', 'care', 'passing', 'medicare', 'program', 'law']\n",
      "Wrote preprocessed data to cache file: preprocessedData.pkl\n",
      "['gun', 'would', 'health', 'immigrants', 'medicare']\n",
      "tensor([[0.1731, 0.1662, 0.1523, 0.1753, 0.1792, 0.1539],\n",
      "        [0.1932, 0.1775, 0.1590, 0.1535, 0.1684, 0.1484],\n",
      "        [0.1924, 0.1628, 0.1577, 0.1465, 0.1789, 0.1617],\n",
      "        [0.1851, 0.1712, 0.1732, 0.1513, 0.1576, 0.1615],\n",
      "        [0.2096, 0.1604, 0.1525, 0.1474, 0.1828, 0.1473],\n",
      "        [0.1659, 0.1913, 0.1487, 0.1712, 0.1558, 0.1671],\n",
      "        [0.1861, 0.1621, 0.1694, 0.1691, 0.1598, 0.1536],\n",
      "        [0.1740, 0.1579, 0.1545, 0.1780, 0.1685, 0.1671],\n",
      "        [0.1666, 0.1526, 0.1715, 0.1750, 0.1791, 0.1553],\n",
      "        [0.1531, 0.1614, 0.1728, 0.1502, 0.1985, 0.1641],\n",
      "        [0.1961, 0.1574, 0.1525, 0.1512, 0.1696, 0.1731],\n",
      "        [0.1919, 0.1536, 0.1772, 0.1633, 0.1722, 0.1418],\n",
      "        [0.1945, 0.1649, 0.1409, 0.1498, 0.1811, 0.1688],\n",
      "        [0.2036, 0.1505, 0.1549, 0.1644, 0.1599, 0.1668],\n",
      "        [0.1911, 0.1576, 0.1632, 0.1538, 0.1724, 0.1618],\n",
      "        [0.1664, 0.1488, 0.1784, 0.1597, 0.1761, 0.1705],\n",
      "        [0.1788, 0.1787, 0.1618, 0.1600, 0.1704, 0.1503],\n",
      "        [0.2027, 0.1574, 0.1688, 0.1530, 0.1629, 0.1552],\n",
      "        [0.1931, 0.1706, 0.1573, 0.1576, 0.1777, 0.1438],\n",
      "        [0.1924, 0.1608, 0.1543, 0.1687, 0.1759, 0.1478],\n",
      "        [0.1787, 0.1738, 0.1459, 0.1798, 0.1581, 0.1637],\n",
      "        [0.1412, 0.1705, 0.1570, 0.1812, 0.1765, 0.1736],\n",
      "        [0.1520, 0.1833, 0.1607, 0.1635, 0.1685, 0.1721],\n",
      "        [0.1440, 0.1680, 0.1677, 0.1917, 0.1535, 0.1751],\n",
      "        [0.1942, 0.1559, 0.1702, 0.1592, 0.1651, 0.1553],\n",
      "        [0.1837, 0.1461, 0.1597, 0.1715, 0.1723, 0.1668],\n",
      "        [0.2173, 0.1522, 0.1579, 0.1475, 0.1638, 0.1613],\n",
      "        [0.1832, 0.1694, 0.1609, 0.1604, 0.1689, 0.1572],\n",
      "        [0.1737, 0.1752, 0.1580, 0.1588, 0.1830, 0.1512],\n",
      "        [0.2066, 0.1610, 0.1655, 0.1323, 0.1701, 0.1646],\n",
      "        [0.1745, 0.1847, 0.1620, 0.1496, 0.1855, 0.1438],\n",
      "        [0.1532, 0.1827, 0.1695, 0.1914, 0.1530, 0.1501],\n",
      "        [0.1935, 0.1466, 0.1760, 0.1517, 0.1660, 0.1662],\n",
      "        [0.1701, 0.1695, 0.1672, 0.1587, 0.1736, 0.1609],\n",
      "        [0.1981, 0.1559, 0.1665, 0.1403, 0.1787, 0.1605],\n",
      "        [0.1953, 0.1616, 0.1550, 0.1588, 0.1555, 0.1738],\n",
      "        [0.1719, 0.1655, 0.1575, 0.1546, 0.1677, 0.1828],\n",
      "        [0.1921, 0.1651, 0.1617, 0.1659, 0.1612, 0.1540],\n",
      "        [0.1856, 0.1678, 0.1540, 0.1548, 0.1754, 0.1623],\n",
      "        [0.1693, 0.1641, 0.1786, 0.1591, 0.1726, 0.1564],\n",
      "        [0.1840, 0.1601, 0.1524, 0.1500, 0.1969, 0.1566],\n",
      "        [0.1945, 0.1749, 0.1527, 0.1409, 0.1664, 0.1707],\n",
      "        [0.1773, 0.1654, 0.1671, 0.1612, 0.1836, 0.1455],\n",
      "        [0.1770, 0.1681, 0.1604, 0.1635, 0.1713, 0.1597],\n",
      "        [0.1774, 0.1621, 0.1767, 0.1721, 0.1562, 0.1554],\n",
      "        [0.1692, 0.1594, 0.1629, 0.1579, 0.1802, 0.1703],\n",
      "        [0.1751, 0.1752, 0.1584, 0.1700, 0.1700, 0.1513],\n",
      "        [0.1828, 0.1605, 0.1429, 0.1527, 0.2009, 0.1603],\n",
      "        [0.1728, 0.1548, 0.1717, 0.1559, 0.1607, 0.1841],\n",
      "        [0.1830, 0.1743, 0.1541, 0.1450, 0.1820, 0.1615]],\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "torch.Size([50, 6])\n",
      "tensor([[0.1797, 0.1810, 0.1505, 0.1477, 0.1660, 0.1751],\n",
      "        [0.1724, 0.1949, 0.1474, 0.1544, 0.1665, 0.1643],\n",
      "        [0.1786, 0.1494, 0.1417, 0.1616, 0.1735, 0.1952],\n",
      "        [0.1716, 0.1972, 0.1469, 0.1370, 0.1616, 0.1858],\n",
      "        [0.1596, 0.1863, 0.1449, 0.1628, 0.1658, 0.1807],\n",
      "        [0.1739, 0.1742, 0.1452, 0.1714, 0.1564, 0.1788],\n",
      "        [0.1643, 0.1618, 0.1531, 0.1663, 0.1635, 0.1911],\n",
      "        [0.1940, 0.1572, 0.1564, 0.1456, 0.1884, 0.1584],\n",
      "        [0.1988, 0.1741, 0.1525, 0.1418, 0.1468, 0.1860],\n",
      "        [0.1634, 0.2142, 0.1552, 0.1493, 0.1586, 0.1593],\n",
      "        [0.1651, 0.1863, 0.1521, 0.1695, 0.1664, 0.1606],\n",
      "        [0.1594, 0.1734, 0.1363, 0.1686, 0.1818, 0.1806],\n",
      "        [0.2071, 0.1659, 0.1501, 0.1443, 0.1684, 0.1641],\n",
      "        [0.1790, 0.1554, 0.1432, 0.1601, 0.1841, 0.1781],\n",
      "        [0.1601, 0.1772, 0.1458, 0.1646, 0.1838, 0.1684],\n",
      "        [0.1767, 0.2049, 0.1554, 0.1439, 0.1499, 0.1693],\n",
      "        [0.1733, 0.1562, 0.1465, 0.1573, 0.1904, 0.1763],\n",
      "        [0.1849, 0.1672, 0.1592, 0.1607, 0.1577, 0.1703],\n",
      "        [0.1868, 0.1689, 0.1651, 0.1573, 0.1433, 0.1785],\n",
      "        [0.1815, 0.2003, 0.1552, 0.1539, 0.1439, 0.1652],\n",
      "        [0.1866, 0.1624, 0.1411, 0.1557, 0.1795, 0.1746],\n",
      "        [0.1944, 0.1735, 0.1405, 0.1524, 0.1863, 0.1529],\n",
      "        [0.1579, 0.1824, 0.1496, 0.1452, 0.1687, 0.1963],\n",
      "        [0.1834, 0.1647, 0.1639, 0.1388, 0.1610, 0.1882],\n",
      "        [0.1664, 0.1878, 0.1369, 0.1607, 0.1552, 0.1930],\n",
      "        [0.1601, 0.2002, 0.1575, 0.1474, 0.1577, 0.1770],\n",
      "        [0.1678, 0.1698, 0.1481, 0.1625, 0.1555, 0.1963],\n",
      "        [0.1729, 0.1743, 0.1423, 0.1634, 0.1551, 0.1919],\n",
      "        [0.1675, 0.1945, 0.1425, 0.1603, 0.1641, 0.1711],\n",
      "        [0.1762, 0.1767, 0.1565, 0.1543, 0.1789, 0.1574],\n",
      "        [0.1876, 0.1623, 0.1458, 0.1506, 0.1747, 0.1789],\n",
      "        [0.1731, 0.1652, 0.1339, 0.1677, 0.1800, 0.1801],\n",
      "        [0.1664, 0.2080, 0.1675, 0.1422, 0.1591, 0.1569],\n",
      "        [0.1841, 0.1636, 0.1484, 0.1703, 0.1708, 0.1628],\n",
      "        [0.1852, 0.1745, 0.1524, 0.1465, 0.1748, 0.1666],\n",
      "        [0.2054, 0.1714, 0.1506, 0.1647, 0.1454, 0.1625],\n",
      "        [0.1661, 0.1887, 0.1472, 0.1632, 0.1515, 0.1833],\n",
      "        [0.1852, 0.1727, 0.1312, 0.1700, 0.1665, 0.1744],\n",
      "        [0.1745, 0.2064, 0.1506, 0.1664, 0.1645, 0.1376],\n",
      "        [0.1826, 0.1771, 0.1542, 0.1486, 0.1643, 0.1731],\n",
      "        [0.1803, 0.1697, 0.1531, 0.1764, 0.1569, 0.1637],\n",
      "        [0.1680, 0.1899, 0.1594, 0.1526, 0.1613, 0.1688],\n",
      "        [0.2166, 0.1726, 0.1640, 0.1337, 0.1602, 0.1529],\n",
      "        [0.1779, 0.1659, 0.1525, 0.1492, 0.1871, 0.1674],\n",
      "        [0.1671, 0.1825, 0.1596, 0.1453, 0.1720, 0.1737],\n",
      "        [0.1709, 0.1791, 0.1467, 0.1461, 0.1653, 0.1919],\n",
      "        [0.1870, 0.1537, 0.1484, 0.1587, 0.1739, 0.1783],\n",
      "        [0.1620, 0.1879, 0.1522, 0.1442, 0.1444, 0.2093],\n",
      "        [0.1661, 0.1820, 0.1365, 0.1826, 0.1512, 0.1816],\n",
      "        [0.1773, 0.1824, 0.1308, 0.1850, 0.1449, 0.1796]],\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "torch.Size([50, 6])\n",
      "tensor([[0.1428, 0.1683, 0.1807, 0.1530, 0.1763, 0.1787],\n",
      "        [0.1786, 0.1565, 0.1534, 0.1572, 0.1654, 0.1889],\n",
      "        [0.1687, 0.1915, 0.1717, 0.1249, 0.1717, 0.1715],\n",
      "        [0.1412, 0.1923, 0.1696, 0.1598, 0.1797, 0.1574],\n",
      "        [0.1718, 0.1672, 0.1656, 0.1541, 0.1704, 0.1709],\n",
      "        [0.1459, 0.1704, 0.1375, 0.1661, 0.1971, 0.1830],\n",
      "        [0.1618, 0.1753, 0.1505, 0.1883, 0.1690, 0.1550],\n",
      "        [0.1611, 0.1866, 0.1459, 0.1580, 0.1641, 0.1842],\n",
      "        [0.1560, 0.1819, 0.1356, 0.1525, 0.2001, 0.1739],\n",
      "        [0.1558, 0.1601, 0.1809, 0.1567, 0.1447, 0.2018],\n",
      "        [0.1318, 0.1773, 0.1472, 0.1615, 0.1976, 0.1846],\n",
      "        [0.1568, 0.1511, 0.1627, 0.1760, 0.1709, 0.1825],\n",
      "        [0.1678, 0.1835, 0.1447, 0.1720, 0.1768, 0.1553],\n",
      "        [0.1740, 0.1883, 0.1380, 0.1461, 0.1916, 0.1619],\n",
      "        [0.1304, 0.1725, 0.1334, 0.1854, 0.1880, 0.1903],\n",
      "        [0.1552, 0.1454, 0.1387, 0.1643, 0.2055, 0.1908],\n",
      "        [0.1638, 0.1750, 0.1434, 0.1676, 0.1623, 0.1878],\n",
      "        [0.1489, 0.1803, 0.1422, 0.1523, 0.1824, 0.1939],\n",
      "        [0.1624, 0.1809, 0.1566, 0.1502, 0.1706, 0.1794],\n",
      "        [0.1689, 0.1710, 0.1600, 0.1626, 0.1753, 0.1622],\n",
      "        [0.1385, 0.1735, 0.1471, 0.1741, 0.1847, 0.1820],\n",
      "        [0.1461, 0.1694, 0.1687, 0.1702, 0.1843, 0.1613],\n",
      "        [0.1625, 0.1755, 0.1629, 0.1529, 0.1641, 0.1821],\n",
      "        [0.1726, 0.1708, 0.1718, 0.1658, 0.1664, 0.1527],\n",
      "        [0.1534, 0.1599, 0.1581, 0.1686, 0.1922, 0.1677],\n",
      "        [0.1674, 0.1527, 0.1756, 0.1647, 0.1714, 0.1682],\n",
      "        [0.1767, 0.1831, 0.1435, 0.1505, 0.1829, 0.1632],\n",
      "        [0.1540, 0.1769, 0.1577, 0.1634, 0.1503, 0.1977],\n",
      "        [0.1553, 0.1961, 0.1614, 0.1499, 0.1596, 0.1777],\n",
      "        [0.1539, 0.1750, 0.1802, 0.1577, 0.1699, 0.1632],\n",
      "        [0.1361, 0.1684, 0.1579, 0.1742, 0.1634, 0.2000],\n",
      "        [0.1348, 0.1706, 0.1611, 0.1689, 0.1674, 0.1972],\n",
      "        [0.1718, 0.1733, 0.1479, 0.1586, 0.1684, 0.1799],\n",
      "        [0.1775, 0.1777, 0.1490, 0.1502, 0.1878, 0.1577],\n",
      "        [0.1603, 0.1737, 0.1686, 0.1564, 0.1685, 0.1724],\n",
      "        [0.1607, 0.1728, 0.1450, 0.1707, 0.1707, 0.1801],\n",
      "        [0.1501, 0.1750, 0.1759, 0.1623, 0.1841, 0.1526],\n",
      "        [0.1496, 0.1532, 0.1572, 0.1786, 0.1684, 0.1931],\n",
      "        [0.1549, 0.1817, 0.1479, 0.1700, 0.1749, 0.1706],\n",
      "        [0.1561, 0.1594, 0.1695, 0.1633, 0.1746, 0.1771],\n",
      "        [0.1333, 0.1813, 0.1718, 0.1633, 0.1663, 0.1840],\n",
      "        [0.1528, 0.1925, 0.1419, 0.1712, 0.1619, 0.1797],\n",
      "        [0.1498, 0.2028, 0.1731, 0.1493, 0.1655, 0.1595],\n",
      "        [0.1573, 0.1677, 0.1612, 0.1644, 0.1688, 0.1807],\n",
      "        [0.1451, 0.1816, 0.1616, 0.1437, 0.1841, 0.1838],\n",
      "        [0.1296, 0.1532, 0.1648, 0.1763, 0.1802, 0.1959],\n",
      "        [0.1813, 0.1562, 0.1521, 0.1721, 0.1518, 0.1865],\n",
      "        [0.1543, 0.1698, 0.1564, 0.1483, 0.1683, 0.2029],\n",
      "        [0.1392, 0.1758, 0.1526, 0.1599, 0.1973, 0.1751],\n",
      "        [0.1413, 0.1770, 0.1549, 0.1410, 0.2042, 0.1815]],\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "torch.Size([50, 6])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1672, 0.1549, 0.1608, 0.1660, 0.1850, 0.1661],\n",
      "        [0.1720, 0.1794, 0.1494, 0.1643, 0.1669, 0.1681],\n",
      "        [0.1473, 0.1668, 0.1659, 0.1732, 0.1700, 0.1767],\n",
      "        [0.1710, 0.1586, 0.1534, 0.1528, 0.1875, 0.1768],\n",
      "        [0.1688, 0.1566, 0.1433, 0.1761, 0.1786, 0.1766],\n",
      "        [0.1666, 0.1701, 0.1558, 0.1789, 0.1810, 0.1475],\n",
      "        [0.1765, 0.1732, 0.1556, 0.1475, 0.1750, 0.1723],\n",
      "        [0.1537, 0.1676, 0.1771, 0.1608, 0.1660, 0.1748],\n",
      "        [0.1731, 0.1690, 0.1662, 0.1652, 0.1655, 0.1609],\n",
      "        [0.1740, 0.1687, 0.1662, 0.1444, 0.1742, 0.1725],\n",
      "        [0.1630, 0.1589, 0.1524, 0.1649, 0.2079, 0.1529],\n",
      "        [0.1611, 0.1920, 0.1620, 0.1554, 0.1562, 0.1733],\n",
      "        [0.1641, 0.1646, 0.1883, 0.1577, 0.1610, 0.1642],\n",
      "        [0.1809, 0.1691, 0.1471, 0.1672, 0.1731, 0.1627],\n",
      "        [0.1798, 0.1624, 0.1432, 0.1646, 0.1612, 0.1888],\n",
      "        [0.1805, 0.1514, 0.1736, 0.1564, 0.1843, 0.1539],\n",
      "        [0.1870, 0.1484, 0.1833, 0.1752, 0.1722, 0.1339],\n",
      "        [0.1723, 0.1883, 0.1705, 0.1708, 0.1447, 0.1535],\n",
      "        [0.1489, 0.1813, 0.1548, 0.1702, 0.1703, 0.1744],\n",
      "        [0.1694, 0.1631, 0.1569, 0.1875, 0.1637, 0.1595],\n",
      "        [0.1584, 0.1841, 0.1698, 0.1639, 0.1526, 0.1713],\n",
      "        [0.1921, 0.1548, 0.1432, 0.1774, 0.1742, 0.1582],\n",
      "        [0.1601, 0.1683, 0.1801, 0.1788, 0.1742, 0.1386],\n",
      "        [0.1592, 0.1611, 0.1635, 0.1618, 0.1892, 0.1651],\n",
      "        [0.1792, 0.1662, 0.1561, 0.1536, 0.1659, 0.1790],\n",
      "        [0.1647, 0.1592, 0.1682, 0.1728, 0.1598, 0.1754],\n",
      "        [0.1538, 0.1616, 0.1647, 0.1779, 0.1949, 0.1472],\n",
      "        [0.1725, 0.1617, 0.1692, 0.1727, 0.1729, 0.1508],\n",
      "        [0.1706, 0.1700, 0.1639, 0.1722, 0.1791, 0.1443],\n",
      "        [0.1758, 0.1716, 0.1436, 0.1632, 0.1624, 0.1833],\n",
      "        [0.1574, 0.1696, 0.1666, 0.1609, 0.1763, 0.1692],\n",
      "        [0.1633, 0.1528, 0.1469, 0.1675, 0.2025, 0.1669],\n",
      "        [0.1549, 0.1612, 0.1658, 0.1667, 0.1809, 0.1705],\n",
      "        [0.1736, 0.1560, 0.1583, 0.1523, 0.1711, 0.1888],\n",
      "        [0.1459, 0.1845, 0.1754, 0.1651, 0.1598, 0.1693],\n",
      "        [0.1617, 0.1904, 0.1538, 0.1620, 0.1683, 0.1639],\n",
      "        [0.1582, 0.1646, 0.1544, 0.1770, 0.1963, 0.1495],\n",
      "        [0.1718, 0.1700, 0.1718, 0.1494, 0.1763, 0.1606],\n",
      "        [0.1736, 0.1579, 0.1613, 0.1743, 0.1695, 0.1633],\n",
      "        [0.1910, 0.1535, 0.1593, 0.1700, 0.1697, 0.1566],\n",
      "        [0.1732, 0.1793, 0.1552, 0.1573, 0.1599, 0.1752],\n",
      "        [0.1682, 0.1530, 0.1828, 0.1568, 0.1804, 0.1588],\n",
      "        [0.1851, 0.1812, 0.1620, 0.1501, 0.1714, 0.1502],\n",
      "        [0.1645, 0.1563, 0.1566, 0.1886, 0.1801, 0.1539],\n",
      "        [0.1560, 0.1546, 0.1434, 0.1575, 0.1952, 0.1933],\n",
      "        [0.1560, 0.1793, 0.1557, 0.1672, 0.1707, 0.1710],\n",
      "        [0.1857, 0.1688, 0.1496, 0.1654, 0.1794, 0.1511],\n",
      "        [0.1589, 0.1551, 0.1624, 0.1738, 0.1719, 0.1778],\n",
      "        [0.1661, 0.1524, 0.1578, 0.1536, 0.1962, 0.1740],\n",
      "        [0.1662, 0.1751, 0.1595, 0.1739, 0.1729, 0.1524]],\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "torch.Size([50, 6])\n",
      "tensor([[0.1731, 0.1605, 0.1774, 0.1476, 0.1603, 0.1812],\n",
      "        [0.1577, 0.1802, 0.1745, 0.1533, 0.1703, 0.1641],\n",
      "        [0.1718, 0.1650, 0.1756, 0.1714, 0.1589, 0.1574],\n",
      "        [0.1584, 0.1637, 0.1604, 0.1748, 0.1556, 0.1870],\n",
      "        [0.1586, 0.1618, 0.1800, 0.1591, 0.1455, 0.1950],\n",
      "        [0.1652, 0.1779, 0.1814, 0.1605, 0.1665, 0.1487],\n",
      "        [0.1322, 0.1854, 0.1772, 0.1588, 0.1695, 0.1769],\n",
      "        [0.1880, 0.1630, 0.1592, 0.1673, 0.1743, 0.1482],\n",
      "        [0.1457, 0.1666, 0.1736, 0.1660, 0.1683, 0.1798],\n",
      "        [0.1603, 0.1720, 0.1817, 0.1447, 0.1508, 0.1904],\n",
      "        [0.1520, 0.1469, 0.1767, 0.1565, 0.1769, 0.1911],\n",
      "        [0.1429, 0.1773, 0.1940, 0.1576, 0.1508, 0.1774],\n",
      "        [0.1352, 0.1907, 0.1883, 0.1633, 0.1499, 0.1726],\n",
      "        [0.1770, 0.1607, 0.1808, 0.1531, 0.1542, 0.1741],\n",
      "        [0.1875, 0.1599, 0.1614, 0.1524, 0.1657, 0.1731],\n",
      "        [0.1396, 0.1749, 0.1591, 0.1640, 0.1754, 0.1870],\n",
      "        [0.1624, 0.1653, 0.1938, 0.1704, 0.1488, 0.1594],\n",
      "        [0.1722, 0.1701, 0.1524, 0.1665, 0.1456, 0.1933],\n",
      "        [0.1740, 0.1567, 0.1879, 0.1509, 0.1591, 0.1715],\n",
      "        [0.1415, 0.1815, 0.1670, 0.1723, 0.1616, 0.1760],\n",
      "        [0.1757, 0.1539, 0.1749, 0.1526, 0.1623, 0.1805],\n",
      "        [0.1563, 0.1666, 0.1835, 0.1799, 0.1414, 0.1723],\n",
      "        [0.1599, 0.1541, 0.1721, 0.1705, 0.1363, 0.2072],\n",
      "        [0.1557, 0.1709, 0.1952, 0.1605, 0.1571, 0.1607],\n",
      "        [0.1924, 0.1520, 0.1918, 0.1468, 0.1554, 0.1615],\n",
      "        [0.1579, 0.1761, 0.1601, 0.1596, 0.1602, 0.1861],\n",
      "        [0.1663, 0.1805, 0.1762, 0.1474, 0.1395, 0.1901],\n",
      "        [0.1713, 0.1626, 0.1687, 0.1901, 0.1402, 0.1671],\n",
      "        [0.1389, 0.1831, 0.1662, 0.1895, 0.1506, 0.1717],\n",
      "        [0.1706, 0.1580, 0.1927, 0.1691, 0.1325, 0.1772],\n",
      "        [0.1457, 0.1708, 0.1636, 0.1581, 0.1655, 0.1963],\n",
      "        [0.1476, 0.1669, 0.1943, 0.1723, 0.1559, 0.1630],\n",
      "        [0.1497, 0.1789, 0.1704, 0.1570, 0.1496, 0.1944],\n",
      "        [0.1440, 0.1669, 0.1706, 0.1676, 0.1555, 0.1954],\n",
      "        [0.1696, 0.1556, 0.1732, 0.1754, 0.1540, 0.1721],\n",
      "        [0.1514, 0.1940, 0.1761, 0.1578, 0.1378, 0.1829],\n",
      "        [0.1592, 0.1629, 0.1928, 0.1518, 0.1594, 0.1739],\n",
      "        [0.1561, 0.1552, 0.1833, 0.1582, 0.1456, 0.2016],\n",
      "        [0.1492, 0.1500, 0.1879, 0.1849, 0.1474, 0.1807],\n",
      "        [0.1703, 0.1780, 0.1666, 0.1526, 0.1443, 0.1881],\n",
      "        [0.1708, 0.1659, 0.1561, 0.1808, 0.1474, 0.1790],\n",
      "        [0.1636, 0.1518, 0.1650, 0.1678, 0.1615, 0.1903],\n",
      "        [0.1646, 0.1805, 0.1722, 0.1531, 0.1486, 0.1809],\n",
      "        [0.1545, 0.1902, 0.1780, 0.1442, 0.1436, 0.1894],\n",
      "        [0.1408, 0.1823, 0.1785, 0.1726, 0.1534, 0.1724],\n",
      "        [0.1517, 0.1762, 0.2014, 0.1559, 0.1508, 0.1640],\n",
      "        [0.1572, 0.1554, 0.1899, 0.1471, 0.1750, 0.1753],\n",
      "        [0.1782, 0.1651, 0.1839, 0.1518, 0.1442, 0.1768],\n",
      "        [0.1636, 0.1612, 0.1759, 0.1634, 0.1558, 0.1801],\n",
      "        [0.1631, 0.1573, 0.1819, 0.1557, 0.1491, 0.1929]],\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "torch.Size([50, 6])\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Initial Variables\n",
    "    topicLabels = {\n",
    "        'pro-immigration': 0,\n",
    "        'anti-immigration': 1,\n",
    "        'pro-guns': 2,\n",
    "        'anti-guns': 3,\n",
    "        'pro-medicare': 4,\n",
    "        'oppose-medicare': 5\n",
    "    }\n",
    "    candidates = ['Biden', 'Buttigieg', 'Klobuchar', 'Sanders', 'Warren', 'Yang']\n",
    "    Out.clear()\n",
    "    \n",
    "    data, labels = parseTrainData(topicLabels, df = pd.read_csv('./data/L3train_nonOneHot.csv'))\n",
    "    \n",
    "    # Let's check out the length of our training data for each category\n",
    "    print(\"Immigration articles: train = {} pro / {} anti\".format(\n",
    "            len(data['train']['pro-immigration']), len(data['train']['anti-immigration'])))\n",
    "    \n",
    "    print(\"Immigration articles: train = {} pro / {} anti\".format(\n",
    "            len(data['train']['pro-guns']), len(data['train']['anti-guns'])))\n",
    "    \n",
    "    print(\"Immigration articles: train = {} pro / {} anti\".format(\n",
    "            len(data['train']['pro-medicare']), len(data['train']['oppose-medicare'])))\n",
    "    \n",
    "    # Below is our prepared shuffled training data\n",
    "    trainX, trainY = prepareTrainData(data, labels)\n",
    "    print(collections.Counter(trainY))\n",
    "    # Below is our test set\n",
    "    testX = prepareTestData(candidates)\n",
    "    \n",
    "    print(\"Sentences (combined): train = {}\".format(len(trainX)))\n",
    "    \n",
    "    # Let's go check out an example from our training data now\n",
    "    print(trainX[100])\n",
    "    \n",
    "    # Applying the tokenizer to get the stems\n",
    "    print(sentenceToWords(trainX[1]))\n",
    "    # Now we preprocess the Data\n",
    "    trainX, trainY = preprocessData(trainX, trainY)\n",
    "    # Build our word Dict\n",
    "    wordDict = buildDict(trainX)\n",
    "    print(list(wordDict.keys())[:5])\n",
    "    \n",
    "    # Save our wordDict\n",
    "    dataDir = '../data/pytorch' # folder to store our data\n",
    "    if not os.path.exists(dataDir): # check to make sure folder exists\n",
    "        print(\"making dataDir folder...\")\n",
    "        os.makedirs(dataDir)\n",
    "    \n",
    "    with open(os.path.join(dataDir, 'wordDict.pkl'), 'wb') as f:\n",
    "        pickle.dump(wordDict, f)\n",
    "    \n",
    "    # Now we pad all the sentences in our training data\n",
    "    trainXNum, trainXLen = convertAndPadData(wordDict, trainX)\n",
    "    \n",
    "    # Pad all the sentences in our testing data?\n",
    "    \n",
    "    # Save our data locally\n",
    "    pd.concat([pd.DataFrame(trainY), pd.DataFrame(trainXLen), pd.DataFrame(trainXNum)], axis=1) \\\n",
    "        .to_csv(os.path.join(dataDir, 'lstm_train.csv'), header=False, index=False)\n",
    "    \n",
    "    # Let's load a small portion of our training dataset for testing\n",
    "    trainSample = pd.read_csv(os.path.join(dataDir, 'lstm_train.csv'), header=None, names=None, nrows=250)\n",
    "    \n",
    "    # Turn input df into tensors\n",
    "    trainSampleY = torch.from_numpy(trainSample[[0]].values).float().squeeze()\n",
    "    trainSampleX = torch.from_numpy(trainSample.drop([0], axis = 1).values).long()\n",
    "    \n",
    "    # Build the dataset\n",
    "    trainSampleDS = torch.utils.data.TensorDataset(trainSampleX, trainSampleY)\n",
    "    # Build the dataloader\n",
    "    trainSampleDL = torch.utils.data.DataLoader(trainSampleDS, batch_size=50)\n",
    "    \n",
    "    # Train the model\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = ConvNet(10).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    for bt in trainSampleDL:\n",
    "        bX, bY = bt\n",
    "\n",
    "        bX = bX.to(device)\n",
    "        bY = bY.to(device)\n",
    "\n",
    "        model = LSTMClassifier(100, 100, 50000).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(bX)\n",
    "        print(output)\n",
    "        print(output.shape)\n",
    "    # train(model, trainSampleDL, 5, optimizer, criterion, device)\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1733, 0.1834, 0.1696, 0.1656, 0.1359, 0.1722],\n",
      "        [0.1610, 0.1884, 0.1714, 0.1526, 0.1457, 0.1810],\n",
      "        [0.1865, 0.1918, 0.1700, 0.1541, 0.1477, 0.1499],\n",
      "        [0.1907, 0.1581, 0.1635, 0.1572, 0.1530, 0.1775],\n",
      "        [0.1827, 0.1669, 0.1594, 0.1589, 0.1565, 0.1756],\n",
      "        [0.1938, 0.1808, 0.1573, 0.1567, 0.1455, 0.1659],\n",
      "        [0.1994, 0.1981, 0.1613, 0.1390, 0.1428, 0.1594],\n",
      "        [0.1855, 0.2037, 0.1696, 0.1492, 0.1375, 0.1545],\n",
      "        [0.1926, 0.1728, 0.1761, 0.1471, 0.1549, 0.1565],\n",
      "        [0.1639, 0.1891, 0.1582, 0.1491, 0.1594, 0.1804],\n",
      "        [0.1656, 0.1695, 0.1541, 0.1684, 0.1480, 0.1943],\n",
      "        [0.1767, 0.1844, 0.1768, 0.1505, 0.1540, 0.1574],\n",
      "        [0.1705, 0.1851, 0.1870, 0.1488, 0.1559, 0.1528],\n",
      "        [0.1784, 0.1722, 0.1840, 0.1426, 0.1362, 0.1865],\n",
      "        [0.1838, 0.1781, 0.1554, 0.1695, 0.1648, 0.1484],\n",
      "        [0.1850, 0.1722, 0.1859, 0.1615, 0.1564, 0.1390],\n",
      "        [0.1618, 0.1718, 0.1902, 0.1626, 0.1497, 0.1639],\n",
      "        [0.1911, 0.1861, 0.1823, 0.1546, 0.1355, 0.1505],\n",
      "        [0.1885, 0.1820, 0.1637, 0.1537, 0.1436, 0.1685],\n",
      "        [0.1793, 0.1715, 0.1758, 0.1811, 0.1373, 0.1551],\n",
      "        [0.1879, 0.1712, 0.1663, 0.1455, 0.1595, 0.1696],\n",
      "        [0.1994, 0.1738, 0.1722, 0.1534, 0.1264, 0.1748],\n",
      "        [0.1810, 0.1777, 0.1743, 0.1691, 0.1254, 0.1725],\n",
      "        [0.1769, 0.1590, 0.1849, 0.1656, 0.1485, 0.1652],\n",
      "        [0.1916, 0.2097, 0.1522, 0.1406, 0.1645, 0.1415],\n",
      "        [0.1587, 0.1852, 0.1681, 0.1545, 0.1472, 0.1862],\n",
      "        [0.1830, 0.1747, 0.1594, 0.1790, 0.1484, 0.1555],\n",
      "        [0.1784, 0.1619, 0.1856, 0.1631, 0.1503, 0.1607],\n",
      "        [0.1878, 0.1576, 0.1832, 0.1689, 0.1581, 0.1444],\n",
      "        [0.1971, 0.1655, 0.1741, 0.1715, 0.1436, 0.1481],\n",
      "        [0.1839, 0.1694, 0.1797, 0.1681, 0.1452, 0.1537],\n",
      "        [0.1853, 0.1785, 0.1707, 0.1563, 0.1550, 0.1543],\n",
      "        [0.1728, 0.1704, 0.1727, 0.1636, 0.1649, 0.1555],\n",
      "        [0.1700, 0.1893, 0.1624, 0.1657, 0.1419, 0.1707],\n",
      "        [0.1902, 0.1648, 0.1827, 0.1683, 0.1525, 0.1415],\n",
      "        [0.1738, 0.1663, 0.2013, 0.1423, 0.1504, 0.1659],\n",
      "        [0.1746, 0.1876, 0.1620, 0.1711, 0.1541, 0.1507],\n",
      "        [0.2038, 0.1811, 0.1543, 0.1610, 0.1443, 0.1555],\n",
      "        [0.1751, 0.1641, 0.1874, 0.1538, 0.1462, 0.1734],\n",
      "        [0.1780, 0.1671, 0.1803, 0.1625, 0.1471, 0.1650],\n",
      "        [0.1608, 0.1899, 0.1870, 0.1505, 0.1588, 0.1529],\n",
      "        [0.1692, 0.1821, 0.1752, 0.1647, 0.1481, 0.1608],\n",
      "        [0.1972, 0.1754, 0.1610, 0.1660, 0.1562, 0.1443],\n",
      "        [0.1883, 0.1650, 0.1646, 0.1719, 0.1471, 0.1632],\n",
      "        [0.1845, 0.1766, 0.1676, 0.1569, 0.1442, 0.1702],\n",
      "        [0.1971, 0.1996, 0.1606, 0.1588, 0.1429, 0.1410],\n",
      "        [0.1784, 0.1676, 0.1620, 0.1687, 0.1658, 0.1575],\n",
      "        [0.1889, 0.1431, 0.1843, 0.1738, 0.1561, 0.1537],\n",
      "        [0.1880, 0.1547, 0.1569, 0.1575, 0.1548, 0.1882],\n",
      "        [0.1637, 0.1994, 0.1592, 0.1553, 0.1487, 0.1738]],\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "torch.Size([50, 6])\n",
      "tensor([[0.1620, 0.1686, 0.1743, 0.1954, 0.1558, 0.1440],\n",
      "        [0.1684, 0.1973, 0.1512, 0.1827, 0.1616, 0.1388],\n",
      "        [0.1427, 0.1577, 0.1851, 0.1685, 0.1755, 0.1705],\n",
      "        [0.1591, 0.1895, 0.1619, 0.1860, 0.1578, 0.1457],\n",
      "        [0.1515, 0.1767, 0.2005, 0.1796, 0.1559, 0.1359],\n",
      "        [0.1652, 0.1867, 0.1658, 0.1695, 0.1546, 0.1582],\n",
      "        [0.1731, 0.1558, 0.1770, 0.1731, 0.1628, 0.1582],\n",
      "        [0.1467, 0.1730, 0.1929, 0.1727, 0.1715, 0.1432],\n",
      "        [0.1391, 0.1675, 0.1792, 0.1860, 0.1538, 0.1745],\n",
      "        [0.1430, 0.1783, 0.1870, 0.1659, 0.1639, 0.1620],\n",
      "        [0.1545, 0.1856, 0.1739, 0.1782, 0.1523, 0.1555],\n",
      "        [0.1746, 0.2114, 0.1681, 0.1629, 0.1370, 0.1459],\n",
      "        [0.1427, 0.1980, 0.1686, 0.1628, 0.1644, 0.1636],\n",
      "        [0.1411, 0.1777, 0.1951, 0.1744, 0.1586, 0.1531],\n",
      "        [0.1532, 0.2003, 0.1754, 0.1777, 0.1479, 0.1456],\n",
      "        [0.1471, 0.1734, 0.1741, 0.1830, 0.1556, 0.1668],\n",
      "        [0.1409, 0.2051, 0.1940, 0.1552, 0.1487, 0.1561],\n",
      "        [0.1484, 0.1904, 0.1567, 0.1790, 0.1640, 0.1614],\n",
      "        [0.1361, 0.1781, 0.1762, 0.1824, 0.1692, 0.1580],\n",
      "        [0.1507, 0.1729, 0.1767, 0.1889, 0.1738, 0.1371],\n",
      "        [0.1450, 0.1606, 0.1747, 0.1932, 0.1647, 0.1618],\n",
      "        [0.1582, 0.1889, 0.1669, 0.1838, 0.1682, 0.1339],\n",
      "        [0.1393, 0.1627, 0.1963, 0.1724, 0.1717, 0.1576],\n",
      "        [0.1517, 0.1650, 0.1934, 0.1813, 0.1718, 0.1368],\n",
      "        [0.1625, 0.1647, 0.1663, 0.1918, 0.1555, 0.1593],\n",
      "        [0.1445, 0.1737, 0.1689, 0.1695, 0.1671, 0.1764],\n",
      "        [0.1637, 0.1685, 0.1732, 0.1770, 0.1729, 0.1448],\n",
      "        [0.1381, 0.1686, 0.1961, 0.1803, 0.1574, 0.1595],\n",
      "        [0.1538, 0.1677, 0.1777, 0.1967, 0.1591, 0.1450],\n",
      "        [0.1595, 0.1627, 0.1855, 0.1833, 0.1518, 0.1572],\n",
      "        [0.1520, 0.1738, 0.1823, 0.1951, 0.1608, 0.1359],\n",
      "        [0.1667, 0.1608, 0.1926, 0.1714, 0.1448, 0.1637],\n",
      "        [0.1585, 0.1659, 0.1606, 0.1843, 0.1702, 0.1606],\n",
      "        [0.1537, 0.1886, 0.1517, 0.1803, 0.1711, 0.1546],\n",
      "        [0.1378, 0.1889, 0.1902, 0.1883, 0.1532, 0.1416],\n",
      "        [0.1602, 0.1805, 0.1636, 0.1812, 0.1628, 0.1516],\n",
      "        [0.1514, 0.1767, 0.1807, 0.1774, 0.1543, 0.1596],\n",
      "        [0.1496, 0.1613, 0.1848, 0.1683, 0.1686, 0.1675],\n",
      "        [0.1726, 0.1681, 0.1735, 0.1694, 0.1576, 0.1588],\n",
      "        [0.1718, 0.1731, 0.1636, 0.1810, 0.1610, 0.1494],\n",
      "        [0.1465, 0.1728, 0.2053, 0.1912, 0.1463, 0.1378],\n",
      "        [0.1392, 0.1914, 0.1724, 0.1705, 0.1624, 0.1641],\n",
      "        [0.1331, 0.1749, 0.1662, 0.1866, 0.1766, 0.1626],\n",
      "        [0.1598, 0.1743, 0.1677, 0.1711, 0.1634, 0.1637],\n",
      "        [0.1479, 0.1833, 0.1805, 0.1724, 0.1512, 0.1647],\n",
      "        [0.1572, 0.1700, 0.1941, 0.1840, 0.1476, 0.1469],\n",
      "        [0.1584, 0.1795, 0.1723, 0.1665, 0.1664, 0.1568],\n",
      "        [0.1534, 0.1740, 0.1788, 0.1924, 0.1573, 0.1441],\n",
      "        [0.1564, 0.1606, 0.1801, 0.1784, 0.1690, 0.1555],\n",
      "        [0.1557, 0.1887, 0.1780, 0.1736, 0.1542, 0.1499]],\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "torch.Size([50, 6])\n",
      "tensor([[0.1733, 0.1950, 0.1628, 0.1700, 0.1495, 0.1495],\n",
      "        [0.1757, 0.1874, 0.1506, 0.1628, 0.1461, 0.1773],\n",
      "        [0.1529, 0.1769, 0.1557, 0.1607, 0.1599, 0.1940],\n",
      "        [0.1566, 0.1621, 0.1467, 0.1992, 0.1520, 0.1835],\n",
      "        [0.1483, 0.1803, 0.1457, 0.1790, 0.1691, 0.1776],\n",
      "        [0.1478, 0.1542, 0.1626, 0.1949, 0.1519, 0.1885],\n",
      "        [0.1660, 0.1682, 0.1606, 0.1541, 0.1545, 0.1966],\n",
      "        [0.1423, 0.1922, 0.1428, 0.2057, 0.1544, 0.1627],\n",
      "        [0.1363, 0.1773, 0.1442, 0.1946, 0.1752, 0.1725],\n",
      "        [0.1663, 0.1953, 0.1568, 0.1652, 0.1555, 0.1609],\n",
      "        [0.1473, 0.1823, 0.1489, 0.1934, 0.1621, 0.1660],\n",
      "        [0.1376, 0.2061, 0.1717, 0.1543, 0.1595, 0.1707],\n",
      "        [0.1636, 0.1792, 0.1509, 0.1774, 0.1579, 0.1711],\n",
      "        [0.1696, 0.1853, 0.1418, 0.1791, 0.1668, 0.1574],\n",
      "        [0.1516, 0.1928, 0.1541, 0.1806, 0.1693, 0.1516],\n",
      "        [0.1528, 0.1864, 0.1449, 0.1710, 0.1787, 0.1663],\n",
      "        [0.1399, 0.1663, 0.1607, 0.1907, 0.1680, 0.1744],\n",
      "        [0.1709, 0.1941, 0.1488, 0.1653, 0.1516, 0.1693],\n",
      "        [0.1541, 0.1632, 0.1583, 0.1490, 0.1862, 0.1892],\n",
      "        [0.1637, 0.1708, 0.1441, 0.1719, 0.1572, 0.1922],\n",
      "        [0.1370, 0.1755, 0.1395, 0.1557, 0.1880, 0.2043],\n",
      "        [0.1276, 0.1866, 0.1728, 0.1760, 0.1604, 0.1766],\n",
      "        [0.1528, 0.1841, 0.1597, 0.1699, 0.1777, 0.1557],\n",
      "        [0.1466, 0.1901, 0.1483, 0.1788, 0.1735, 0.1627],\n",
      "        [0.1600, 0.1704, 0.1507, 0.1616, 0.1745, 0.1827],\n",
      "        [0.1747, 0.1781, 0.1563, 0.1655, 0.1600, 0.1655],\n",
      "        [0.1428, 0.1648, 0.1373, 0.2039, 0.1670, 0.1842],\n",
      "        [0.1593, 0.1786, 0.1691, 0.1765, 0.1507, 0.1659],\n",
      "        [0.1539, 0.1755, 0.1500, 0.1868, 0.1709, 0.1629],\n",
      "        [0.1511, 0.1668, 0.1528, 0.1822, 0.1700, 0.1771],\n",
      "        [0.1336, 0.1753, 0.1673, 0.1740, 0.1786, 0.1712],\n",
      "        [0.1465, 0.1685, 0.1600, 0.1789, 0.1707, 0.1754],\n",
      "        [0.1599, 0.1795, 0.1664, 0.1706, 0.1661, 0.1575],\n",
      "        [0.1470, 0.1873, 0.1609, 0.1599, 0.1646, 0.1802],\n",
      "        [0.1270, 0.1668, 0.1365, 0.1884, 0.1708, 0.2105],\n",
      "        [0.1482, 0.1772, 0.1481, 0.1813, 0.1703, 0.1749],\n",
      "        [0.1605, 0.1496, 0.1563, 0.1858, 0.1708, 0.1770],\n",
      "        [0.1473, 0.1770, 0.1523, 0.1882, 0.1700, 0.1652],\n",
      "        [0.1456, 0.1645, 0.1493, 0.1637, 0.1913, 0.1857],\n",
      "        [0.1651, 0.1718, 0.1651, 0.1661, 0.1697, 0.1623],\n",
      "        [0.1543, 0.1668, 0.1558, 0.1783, 0.1782, 0.1667],\n",
      "        [0.1706, 0.1726, 0.1540, 0.1580, 0.1691, 0.1758],\n",
      "        [0.1595, 0.1820, 0.1491, 0.1633, 0.1673, 0.1788],\n",
      "        [0.1461, 0.1794, 0.1459, 0.1847, 0.1650, 0.1790],\n",
      "        [0.1594, 0.1490, 0.1480, 0.1957, 0.1707, 0.1772],\n",
      "        [0.1462, 0.1682, 0.1395, 0.1817, 0.1720, 0.1924],\n",
      "        [0.1620, 0.1669, 0.1505, 0.1818, 0.1643, 0.1744],\n",
      "        [0.1493, 0.1897, 0.1598, 0.1594, 0.1720, 0.1699],\n",
      "        [0.1901, 0.1763, 0.1565, 0.1494, 0.1424, 0.1852],\n",
      "        [0.1644, 0.1557, 0.1613, 0.1821, 0.1496, 0.1868]],\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "torch.Size([50, 6])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1721, 0.1628, 0.1590, 0.1578, 0.1613, 0.1870],\n",
      "        [0.1797, 0.1455, 0.1505, 0.1557, 0.1778, 0.1908],\n",
      "        [0.1727, 0.1632, 0.1708, 0.1450, 0.1705, 0.1779],\n",
      "        [0.1608, 0.1524, 0.1471, 0.1719, 0.2007, 0.1671],\n",
      "        [0.1884, 0.1405, 0.1391, 0.1570, 0.1941, 0.1809],\n",
      "        [0.1905, 0.1534, 0.1528, 0.1702, 0.1531, 0.1799],\n",
      "        [0.1909, 0.1662, 0.1473, 0.1711, 0.1486, 0.1759],\n",
      "        [0.1757, 0.1564, 0.1711, 0.1598, 0.1556, 0.1814],\n",
      "        [0.1465, 0.1577, 0.1629, 0.1845, 0.1711, 0.1774],\n",
      "        [0.1744, 0.1643, 0.1738, 0.1566, 0.1590, 0.1719],\n",
      "        [0.1704, 0.1940, 0.1569, 0.1482, 0.1570, 0.1736],\n",
      "        [0.1886, 0.1433, 0.1690, 0.1660, 0.1699, 0.1632],\n",
      "        [0.1682, 0.1653, 0.1634, 0.1521, 0.1751, 0.1759],\n",
      "        [0.1707, 0.1653, 0.1477, 0.1465, 0.1815, 0.1884],\n",
      "        [0.1547, 0.1547, 0.1756, 0.1728, 0.1816, 0.1606],\n",
      "        [0.1916, 0.1647, 0.1457, 0.1612, 0.1469, 0.1898],\n",
      "        [0.1598, 0.1590, 0.1641, 0.1872, 0.1754, 0.1545],\n",
      "        [0.1453, 0.1734, 0.1548, 0.1711, 0.1514, 0.2040],\n",
      "        [0.1553, 0.1761, 0.1583, 0.1769, 0.1701, 0.1633],\n",
      "        [0.1454, 0.1592, 0.1637, 0.1580, 0.1765, 0.1972],\n",
      "        [0.1695, 0.1447, 0.1732, 0.1548, 0.1819, 0.1759],\n",
      "        [0.1925, 0.1510, 0.1376, 0.1561, 0.1764, 0.1864],\n",
      "        [0.1633, 0.1580, 0.1492, 0.1701, 0.1638, 0.1957],\n",
      "        [0.1831, 0.1476, 0.1742, 0.1807, 0.1457, 0.1686],\n",
      "        [0.1727, 0.1702, 0.1407, 0.1683, 0.1684, 0.1797],\n",
      "        [0.1606, 0.1495, 0.1562, 0.1868, 0.1608, 0.1861],\n",
      "        [0.1738, 0.1598, 0.1727, 0.1622, 0.1670, 0.1646],\n",
      "        [0.1742, 0.1371, 0.1545, 0.1916, 0.1644, 0.1782],\n",
      "        [0.1758, 0.1554, 0.1778, 0.1631, 0.1700, 0.1578],\n",
      "        [0.1582, 0.1496, 0.1652, 0.1719, 0.1736, 0.1815],\n",
      "        [0.1664, 0.1459, 0.1626, 0.1682, 0.1767, 0.1802],\n",
      "        [0.1536, 0.1678, 0.1674, 0.1668, 0.1819, 0.1625],\n",
      "        [0.1699, 0.1574, 0.1611, 0.1684, 0.1728, 0.1704],\n",
      "        [0.1637, 0.1652, 0.1686, 0.1640, 0.1612, 0.1772],\n",
      "        [0.1766, 0.1784, 0.1439, 0.1436, 0.1880, 0.1696],\n",
      "        [0.1630, 0.1582, 0.1598, 0.1887, 0.1661, 0.1643],\n",
      "        [0.1548, 0.1749, 0.1617, 0.1843, 0.1577, 0.1666],\n",
      "        [0.1748, 0.1619, 0.1652, 0.1755, 0.1571, 0.1654],\n",
      "        [0.1643, 0.1559, 0.1529, 0.1648, 0.1788, 0.1832],\n",
      "        [0.1717, 0.1649, 0.1573, 0.1587, 0.1816, 0.1658],\n",
      "        [0.1575, 0.1659, 0.1733, 0.1498, 0.1778, 0.1758],\n",
      "        [0.1737, 0.1636, 0.1528, 0.1620, 0.1901, 0.1579],\n",
      "        [0.1955, 0.1574, 0.1434, 0.1493, 0.1913, 0.1631],\n",
      "        [0.1669, 0.1503, 0.1720, 0.1642, 0.1789, 0.1677],\n",
      "        [0.2012, 0.1472, 0.1370, 0.1691, 0.1650, 0.1804],\n",
      "        [0.1913, 0.1714, 0.1472, 0.1610, 0.1668, 0.1623],\n",
      "        [0.1656, 0.1776, 0.1668, 0.1514, 0.1654, 0.1732],\n",
      "        [0.1906, 0.1555, 0.1577, 0.1717, 0.1682, 0.1563],\n",
      "        [0.1477, 0.1679, 0.1403, 0.1511, 0.2081, 0.1848],\n",
      "        [0.1830, 0.1649, 0.1639, 0.1507, 0.1887, 0.1487]],\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "torch.Size([50, 6])\n",
      "tensor([[0.1726, 0.1686, 0.1666, 0.1823, 0.1387, 0.1712],\n",
      "        [0.1557, 0.1684, 0.1691, 0.1946, 0.1604, 0.1518],\n",
      "        [0.1905, 0.1428, 0.1439, 0.1822, 0.1763, 0.1643],\n",
      "        [0.1922, 0.1630, 0.1613, 0.1603, 0.1566, 0.1665],\n",
      "        [0.1875, 0.1686, 0.1702, 0.1849, 0.1492, 0.1396],\n",
      "        [0.1690, 0.1626, 0.1749, 0.1825, 0.1621, 0.1490],\n",
      "        [0.1721, 0.1679, 0.1415, 0.1953, 0.1647, 0.1585],\n",
      "        [0.1672, 0.1530, 0.1633, 0.1757, 0.1631, 0.1777],\n",
      "        [0.1670, 0.1317, 0.2006, 0.1885, 0.1489, 0.1633],\n",
      "        [0.1756, 0.1796, 0.1646, 0.1730, 0.1635, 0.1437],\n",
      "        [0.1801, 0.1568, 0.1583, 0.1773, 0.1574, 0.1701],\n",
      "        [0.1743, 0.1611, 0.1489, 0.1885, 0.1548, 0.1725],\n",
      "        [0.1553, 0.1564, 0.1641, 0.2033, 0.1643, 0.1566],\n",
      "        [0.1578, 0.1501, 0.1596, 0.1996, 0.1920, 0.1410],\n",
      "        [0.1820, 0.1490, 0.1806, 0.1429, 0.1793, 0.1662],\n",
      "        [0.1611, 0.1548, 0.1624, 0.1814, 0.1731, 0.1672],\n",
      "        [0.1839, 0.1700, 0.1512, 0.1703, 0.1597, 0.1649],\n",
      "        [0.1647, 0.1637, 0.1575, 0.1818, 0.1761, 0.1563],\n",
      "        [0.1759, 0.1672, 0.1523, 0.1838, 0.1609, 0.1598],\n",
      "        [0.1678, 0.1541, 0.1794, 0.1815, 0.1673, 0.1499],\n",
      "        [0.1593, 0.1587, 0.1538, 0.2056, 0.1745, 0.1482],\n",
      "        [0.1717, 0.1551, 0.1644, 0.1800, 0.1674, 0.1614],\n",
      "        [0.1853, 0.1537, 0.1669, 0.1751, 0.1495, 0.1695],\n",
      "        [0.1926, 0.1562, 0.1604, 0.1854, 0.1536, 0.1518],\n",
      "        [0.1925, 0.1529, 0.1470, 0.1893, 0.1497, 0.1686],\n",
      "        [0.1670, 0.1634, 0.1577, 0.1885, 0.1611, 0.1623],\n",
      "        [0.1647, 0.1645, 0.1660, 0.1765, 0.1884, 0.1398],\n",
      "        [0.1707, 0.1351, 0.1720, 0.1884, 0.1697, 0.1642],\n",
      "        [0.1732, 0.1617, 0.1551, 0.1913, 0.1673, 0.1514],\n",
      "        [0.1641, 0.1583, 0.1756, 0.1697, 0.1763, 0.1560],\n",
      "        [0.1628, 0.1767, 0.1645, 0.1939, 0.1612, 0.1409],\n",
      "        [0.1712, 0.1522, 0.1537, 0.2001, 0.1389, 0.1839],\n",
      "        [0.1855, 0.1610, 0.1547, 0.1694, 0.1661, 0.1633],\n",
      "        [0.1850, 0.1514, 0.1721, 0.1838, 0.1493, 0.1584],\n",
      "        [0.1848, 0.1603, 0.1591, 0.1774, 0.1476, 0.1708],\n",
      "        [0.1731, 0.1689, 0.1441, 0.1975, 0.1697, 0.1468],\n",
      "        [0.1514, 0.1598, 0.1673, 0.1911, 0.1771, 0.1533],\n",
      "        [0.1723, 0.1722, 0.1709, 0.1800, 0.1451, 0.1595],\n",
      "        [0.1768, 0.1642, 0.1501, 0.1767, 0.1781, 0.1541],\n",
      "        [0.1514, 0.1632, 0.1620, 0.2077, 0.1558, 0.1600],\n",
      "        [0.1692, 0.1766, 0.1513, 0.1709, 0.1757, 0.1564],\n",
      "        [0.1655, 0.1651, 0.1593, 0.1802, 0.1776, 0.1522],\n",
      "        [0.1828, 0.1491, 0.1731, 0.1861, 0.1518, 0.1571],\n",
      "        [0.1345, 0.1481, 0.1819, 0.1853, 0.1837, 0.1666],\n",
      "        [0.1596, 0.1556, 0.1660, 0.1786, 0.1629, 0.1773],\n",
      "        [0.1880, 0.1488, 0.1640, 0.1680, 0.1575, 0.1738],\n",
      "        [0.1404, 0.1422, 0.1627, 0.1973, 0.1737, 0.1837],\n",
      "        [0.1488, 0.1616, 0.1716, 0.1817, 0.1658, 0.1704],\n",
      "        [0.1789, 0.1634, 0.1682, 0.1612, 0.1586, 0.1697],\n",
      "        [0.1716, 0.1626, 0.1582, 0.1745, 0.1714, 0.1616]],\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "torch.Size([50, 6])\n",
      "tensor([[0.1578, 0.1463, 0.1883, 0.1982, 0.1459, 0.1636],\n",
      "        [0.1514, 0.1551, 0.1881, 0.1549, 0.1548, 0.1958],\n",
      "        [0.1590, 0.1760, 0.1964, 0.1505, 0.1456, 0.1724],\n",
      "        [0.1381, 0.1708, 0.2144, 0.1613, 0.1364, 0.1790],\n",
      "        [0.1429, 0.1721, 0.1747, 0.1793, 0.1331, 0.1980],\n",
      "        [0.1638, 0.1386, 0.1676, 0.2001, 0.1501, 0.1798],\n",
      "        [0.1491, 0.1530, 0.1658, 0.1861, 0.1520, 0.1941],\n",
      "        [0.1531, 0.1639, 0.1659, 0.1910, 0.1576, 0.1685],\n",
      "        [0.1464, 0.1379, 0.1720, 0.1998, 0.1596, 0.1843],\n",
      "        [0.1465, 0.1782, 0.1693, 0.1816, 0.1527, 0.1716],\n",
      "        [0.1498, 0.1702, 0.1726, 0.1838, 0.1428, 0.1808],\n",
      "        [0.1595, 0.1625, 0.1886, 0.1727, 0.1522, 0.1644],\n",
      "        [0.1342, 0.1708, 0.1941, 0.1512, 0.1350, 0.2148],\n",
      "        [0.1621, 0.1615, 0.1716, 0.1798, 0.1531, 0.1718],\n",
      "        [0.1319, 0.1769, 0.1797, 0.1507, 0.1584, 0.2023],\n",
      "        [0.1640, 0.1825, 0.1921, 0.1610, 0.1371, 0.1634],\n",
      "        [0.1545, 0.1573, 0.1874, 0.1570, 0.1660, 0.1779],\n",
      "        [0.1489, 0.1477, 0.1835, 0.1665, 0.1521, 0.2012],\n",
      "        [0.1621, 0.1496, 0.1824, 0.1807, 0.1562, 0.1690],\n",
      "        [0.1419, 0.1599, 0.1709, 0.1874, 0.1655, 0.1744],\n",
      "        [0.1535, 0.1548, 0.1785, 0.1662, 0.1504, 0.1966],\n",
      "        [0.1415, 0.1633, 0.1918, 0.1539, 0.1689, 0.1805],\n",
      "        [0.1482, 0.1687, 0.1771, 0.1608, 0.1740, 0.1714],\n",
      "        [0.1394, 0.1519, 0.1845, 0.1714, 0.1553, 0.1974],\n",
      "        [0.1588, 0.1565, 0.1690, 0.1904, 0.1584, 0.1669],\n",
      "        [0.1377, 0.1755, 0.2127, 0.1438, 0.1354, 0.1948],\n",
      "        [0.1627, 0.1487, 0.1805, 0.1843, 0.1550, 0.1687],\n",
      "        [0.1481, 0.1712, 0.1788, 0.1625, 0.1459, 0.1936],\n",
      "        [0.1305, 0.1639, 0.1749, 0.1743, 0.1534, 0.2031],\n",
      "        [0.1560, 0.1490, 0.1837, 0.1651, 0.1634, 0.1829],\n",
      "        [0.1514, 0.1689, 0.1966, 0.1732, 0.1526, 0.1573],\n",
      "        [0.1495, 0.1783, 0.1824, 0.1761, 0.1434, 0.1703],\n",
      "        [0.1427, 0.1740, 0.1906, 0.1577, 0.1504, 0.1845],\n",
      "        [0.1338, 0.1791, 0.1749, 0.1653, 0.1340, 0.2129],\n",
      "        [0.1740, 0.1526, 0.1732, 0.1571, 0.1681, 0.1749],\n",
      "        [0.1675, 0.1636, 0.1678, 0.1627, 0.1698, 0.1686],\n",
      "        [0.1774, 0.1695, 0.1609, 0.1777, 0.1452, 0.1693],\n",
      "        [0.1555, 0.1614, 0.1961, 0.1481, 0.1356, 0.2033],\n",
      "        [0.1356, 0.1766, 0.1924, 0.1552, 0.1479, 0.1924],\n",
      "        [0.1680, 0.1781, 0.1741, 0.1606, 0.1497, 0.1695],\n",
      "        [0.1439, 0.1577, 0.1539, 0.1819, 0.1680, 0.1946],\n",
      "        [0.1399, 0.1639, 0.1762, 0.1821, 0.1545, 0.1835],\n",
      "        [0.1526, 0.1567, 0.1795, 0.1899, 0.1441, 0.1773],\n",
      "        [0.1729, 0.1521, 0.1833, 0.1801, 0.1435, 0.1680],\n",
      "        [0.1675, 0.1557, 0.1713, 0.1779, 0.1646, 0.1630],\n",
      "        [0.1596, 0.1560, 0.1879, 0.1590, 0.1439, 0.1936],\n",
      "        [0.1343, 0.1617, 0.1873, 0.1712, 0.1586, 0.1870],\n",
      "        [0.1375, 0.1672, 0.1752, 0.1710, 0.1634, 0.1856],\n",
      "        [0.1399, 0.1591, 0.1739, 0.1754, 0.1504, 0.2013],\n",
      "        [0.1515, 0.1400, 0.1752, 0.1885, 0.1627, 0.1821]],\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "torch.Size([50, 6])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1411, 0.1885, 0.1980, 0.1850, 0.1525, 0.1349],\n",
      "        [0.1607, 0.1865, 0.1540, 0.1813, 0.1650, 0.1526],\n",
      "        [0.1670, 0.1757, 0.1891, 0.1612, 0.1638, 0.1432],\n",
      "        [0.1645, 0.1720, 0.1968, 0.1669, 0.1565, 0.1432],\n",
      "        [0.1427, 0.1575, 0.1837, 0.1837, 0.1511, 0.1814],\n",
      "        [0.1634, 0.1642, 0.1686, 0.1875, 0.1515, 0.1648],\n",
      "        [0.1540, 0.1880, 0.1625, 0.1843, 0.1723, 0.1389],\n",
      "        [0.1519, 0.1655, 0.1737, 0.1698, 0.1905, 0.1486],\n",
      "        [0.1491, 0.1917, 0.1937, 0.1710, 0.1597, 0.1349],\n",
      "        [0.1610, 0.1779, 0.1866, 0.1530, 0.1596, 0.1619],\n",
      "        [0.1533, 0.1897, 0.1574, 0.1810, 0.1816, 0.1369],\n",
      "        [0.1678, 0.1797, 0.1555, 0.1829, 0.1579, 0.1562],\n",
      "        [0.1510, 0.1675, 0.1645, 0.1861, 0.1631, 0.1678],\n",
      "        [0.1476, 0.1695, 0.1771, 0.1838, 0.1507, 0.1713],\n",
      "        [0.1428, 0.1677, 0.1491, 0.1914, 0.1619, 0.1872],\n",
      "        [0.1511, 0.1834, 0.1847, 0.1662, 0.1684, 0.1461],\n",
      "        [0.1497, 0.1820, 0.1844, 0.1810, 0.1556, 0.1474],\n",
      "        [0.1614, 0.1732, 0.1614, 0.1814, 0.1569, 0.1658],\n",
      "        [0.1572, 0.1892, 0.1637, 0.1924, 0.1455, 0.1520],\n",
      "        [0.1578, 0.1672, 0.1837, 0.1814, 0.1518, 0.1581],\n",
      "        [0.1374, 0.1757, 0.1930, 0.1735, 0.1670, 0.1533],\n",
      "        [0.1489, 0.1747, 0.1777, 0.1607, 0.1739, 0.1641],\n",
      "        [0.1437, 0.1752, 0.1843, 0.1767, 0.1526, 0.1675],\n",
      "        [0.1543, 0.1624, 0.1692, 0.1970, 0.1532, 0.1639],\n",
      "        [0.1917, 0.1688, 0.1851, 0.1883, 0.1292, 0.1369],\n",
      "        [0.1507, 0.1816, 0.1588, 0.1750, 0.1765, 0.1573],\n",
      "        [0.1536, 0.1732, 0.1630, 0.1931, 0.1509, 0.1662],\n",
      "        [0.1529, 0.1776, 0.1785, 0.1657, 0.1764, 0.1489],\n",
      "        [0.1589, 0.1584, 0.1672, 0.1868, 0.1590, 0.1697],\n",
      "        [0.1701, 0.1839, 0.1624, 0.1521, 0.1681, 0.1634],\n",
      "        [0.1510, 0.1532, 0.1713, 0.1919, 0.1624, 0.1701],\n",
      "        [0.1486, 0.1780, 0.1729, 0.1851, 0.1598, 0.1557],\n",
      "        [0.1341, 0.1839, 0.1771, 0.1765, 0.1694, 0.1589],\n",
      "        [0.1539, 0.1753, 0.1753, 0.1694, 0.1484, 0.1777],\n",
      "        [0.1362, 0.1612, 0.1907, 0.1842, 0.1652, 0.1624],\n",
      "        [0.1445, 0.1829, 0.1808, 0.1756, 0.1573, 0.1590],\n",
      "        [0.1537, 0.1683, 0.1719, 0.1804, 0.1719, 0.1538],\n",
      "        [0.1562, 0.1754, 0.1772, 0.1751, 0.1464, 0.1696],\n",
      "        [0.1648, 0.1812, 0.1759, 0.1675, 0.1537, 0.1569],\n",
      "        [0.1549, 0.1823, 0.1717, 0.1650, 0.1728, 0.1533],\n",
      "        [0.1509, 0.1684, 0.1875, 0.1736, 0.1415, 0.1781],\n",
      "        [0.1614, 0.1788, 0.1729, 0.1629, 0.1766, 0.1474],\n",
      "        [0.1580, 0.1706, 0.1728, 0.1939, 0.1508, 0.1539],\n",
      "        [0.1588, 0.1797, 0.1608, 0.1863, 0.1505, 0.1639],\n",
      "        [0.1466, 0.1934, 0.1554, 0.1801, 0.1786, 0.1459],\n",
      "        [0.1491, 0.1781, 0.1810, 0.1738, 0.1720, 0.1460],\n",
      "        [0.1606, 0.1575, 0.1677, 0.1888, 0.1729, 0.1526],\n",
      "        [0.1745, 0.1675, 0.1567, 0.1643, 0.1733, 0.1636],\n",
      "        [0.1538, 0.1845, 0.1748, 0.1785, 0.1606, 0.1478],\n",
      "        [0.1635, 0.1921, 0.1539, 0.1755, 0.1660, 0.1490]],\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "torch.Size([50, 6])\n",
      "tensor([[0.1551, 0.1599, 0.1696, 0.1664, 0.1710, 0.1780],\n",
      "        [0.1457, 0.1570, 0.1522, 0.1889, 0.1893, 0.1669],\n",
      "        [0.1927, 0.1635, 0.1591, 0.1403, 0.1776, 0.1668],\n",
      "        [0.1615, 0.1485, 0.1777, 0.1489, 0.1729, 0.1904],\n",
      "        [0.1568, 0.1429, 0.1543, 0.1782, 0.1842, 0.1837],\n",
      "        [0.1704, 0.1498, 0.1600, 0.1876, 0.1603, 0.1719],\n",
      "        [0.1576, 0.1552, 0.1433, 0.1597, 0.1944, 0.1897],\n",
      "        [0.1550, 0.1587, 0.1672, 0.1747, 0.1660, 0.1783],\n",
      "        [0.1619, 0.1682, 0.1594, 0.1657, 0.1670, 0.1779],\n",
      "        [0.1621, 0.1612, 0.1318, 0.1792, 0.1821, 0.1837],\n",
      "        [0.1678, 0.1543, 0.1677, 0.1666, 0.1685, 0.1751],\n",
      "        [0.1638, 0.1691, 0.1585, 0.1477, 0.1905, 0.1705],\n",
      "        [0.1412, 0.1601, 0.1642, 0.1878, 0.1770, 0.1697],\n",
      "        [0.1608, 0.1603, 0.1773, 0.1521, 0.1795, 0.1699],\n",
      "        [0.1471, 0.1696, 0.1466, 0.1712, 0.1692, 0.1962],\n",
      "        [0.1476, 0.1654, 0.1663, 0.1838, 0.1794, 0.1576],\n",
      "        [0.1405, 0.1601, 0.1475, 0.1629, 0.1988, 0.1901],\n",
      "        [0.1577, 0.1552, 0.1626, 0.1535, 0.1723, 0.1987],\n",
      "        [0.1585, 0.1617, 0.1478, 0.1753, 0.1822, 0.1744],\n",
      "        [0.1568, 0.1688, 0.1642, 0.1777, 0.1676, 0.1650],\n",
      "        [0.1425, 0.1574, 0.1565, 0.1855, 0.1805, 0.1777],\n",
      "        [0.1458, 0.1623, 0.1616, 0.1863, 0.1857, 0.1582],\n",
      "        [0.1457, 0.1629, 0.1459, 0.1945, 0.1721, 0.1789],\n",
      "        [0.1358, 0.1516, 0.1613, 0.1830, 0.1747, 0.1936],\n",
      "        [0.1569, 0.1728, 0.1523, 0.1642, 0.1945, 0.1593],\n",
      "        [0.1431, 0.1591, 0.1437, 0.1837, 0.1980, 0.1724],\n",
      "        [0.1612, 0.1735, 0.1689, 0.1436, 0.1608, 0.1921],\n",
      "        [0.1915, 0.1725, 0.1641, 0.1388, 0.1662, 0.1669],\n",
      "        [0.1630, 0.1794, 0.1555, 0.1614, 0.1671, 0.1735],\n",
      "        [0.1464, 0.1596, 0.1516, 0.1721, 0.1919, 0.1785],\n",
      "        [0.1543, 0.1763, 0.1436, 0.1657, 0.1792, 0.1808],\n",
      "        [0.1600, 0.1625, 0.1565, 0.1707, 0.1749, 0.1754],\n",
      "        [0.1564, 0.1628, 0.1474, 0.1613, 0.1956, 0.1766],\n",
      "        [0.1455, 0.1544, 0.1540, 0.1950, 0.1805, 0.1706],\n",
      "        [0.1659, 0.1720, 0.1566, 0.1719, 0.1609, 0.1727],\n",
      "        [0.1590, 0.1554, 0.1538, 0.1721, 0.1893, 0.1704],\n",
      "        [0.1622, 0.1699, 0.1361, 0.1678, 0.1765, 0.1874],\n",
      "        [0.1583, 0.1527, 0.1602, 0.1849, 0.1882, 0.1557],\n",
      "        [0.1823, 0.1598, 0.1490, 0.1554, 0.1611, 0.1924],\n",
      "        [0.1301, 0.1663, 0.1607, 0.1608, 0.2102, 0.1719],\n",
      "        [0.1712, 0.1493, 0.1495, 0.1918, 0.1648, 0.1734],\n",
      "        [0.1555, 0.1531, 0.1630, 0.1562, 0.1896, 0.1827],\n",
      "        [0.1598, 0.1644, 0.1513, 0.1852, 0.1621, 0.1771],\n",
      "        [0.1502, 0.1701, 0.1349, 0.1956, 0.1794, 0.1698],\n",
      "        [0.1569, 0.1716, 0.1644, 0.1665, 0.1627, 0.1779],\n",
      "        [0.1650, 0.1470, 0.1619, 0.1748, 0.1598, 0.1915],\n",
      "        [0.1806, 0.1448, 0.1747, 0.1438, 0.1561, 0.2000],\n",
      "        [0.1333, 0.1546, 0.1712, 0.1814, 0.1659, 0.1935],\n",
      "        [0.1647, 0.1537, 0.1472, 0.1613, 0.1953, 0.1778],\n",
      "        [0.1686, 0.1665, 0.1454, 0.1644, 0.1663, 0.1889]],\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "torch.Size([50, 6])\n",
      "tensor([[0.1765, 0.1682, 0.1695, 0.1723, 0.1307, 0.1828],\n",
      "        [0.1557, 0.1742, 0.1808, 0.1714, 0.1660, 0.1518],\n",
      "        [0.1905, 0.1475, 0.1780, 0.1539, 0.1534, 0.1767],\n",
      "        [0.1560, 0.1850, 0.1745, 0.1441, 0.1654, 0.1750],\n",
      "        [0.1849, 0.1727, 0.1578, 0.1778, 0.1390, 0.1677],\n",
      "        [0.1580, 0.1708, 0.1889, 0.1721, 0.1493, 0.1609],\n",
      "        [0.1789, 0.1792, 0.1736, 0.1612, 0.1498, 0.1572],\n",
      "        [0.1633, 0.1910, 0.1799, 0.1647, 0.1416, 0.1595],\n",
      "        [0.1731, 0.1684, 0.1735, 0.1432, 0.1568, 0.1850],\n",
      "        [0.1865, 0.1548, 0.1706, 0.1720, 0.1412, 0.1750],\n",
      "        [0.1545, 0.1832, 0.1949, 0.1609, 0.1621, 0.1443],\n",
      "        [0.1710, 0.1798, 0.1942, 0.1542, 0.1381, 0.1627],\n",
      "        [0.1967, 0.1624, 0.1665, 0.1579, 0.1623, 0.1542],\n",
      "        [0.1639, 0.1491, 0.1558, 0.1895, 0.1663, 0.1753],\n",
      "        [0.1688, 0.1636, 0.1778, 0.1689, 0.1507, 0.1702],\n",
      "        [0.1684, 0.1690, 0.1748, 0.1499, 0.1691, 0.1687],\n",
      "        [0.1789, 0.1397, 0.1755, 0.1666, 0.1646, 0.1748],\n",
      "        [0.1614, 0.1708, 0.1465, 0.1733, 0.1657, 0.1822],\n",
      "        [0.1831, 0.1676, 0.1655, 0.1687, 0.1518, 0.1633],\n",
      "        [0.1686, 0.1639, 0.1537, 0.1791, 0.1636, 0.1710],\n",
      "        [0.1475, 0.1824, 0.1710, 0.1646, 0.1509, 0.1836],\n",
      "        [0.1550, 0.1701, 0.1527, 0.1611, 0.1972, 0.1640],\n",
      "        [0.1693, 0.1535, 0.2001, 0.1683, 0.1527, 0.1561],\n",
      "        [0.1643, 0.1585, 0.1876, 0.1699, 0.1497, 0.1700],\n",
      "        [0.1586, 0.1803, 0.1768, 0.1263, 0.1758, 0.1822],\n",
      "        [0.1595, 0.1655, 0.1628, 0.1882, 0.1482, 0.1758],\n",
      "        [0.1679, 0.1685, 0.1680, 0.1792, 0.1465, 0.1700],\n",
      "        [0.1659, 0.1863, 0.1589, 0.1684, 0.1627, 0.1578],\n",
      "        [0.1939, 0.1688, 0.1569, 0.1720, 0.1386, 0.1699],\n",
      "        [0.1852, 0.1566, 0.1805, 0.1689, 0.1547, 0.1540],\n",
      "        [0.1568, 0.1772, 0.1837, 0.1432, 0.1659, 0.1731],\n",
      "        [0.1745, 0.1914, 0.1826, 0.1428, 0.1486, 0.1601],\n",
      "        [0.1707, 0.1564, 0.1851, 0.1733, 0.1483, 0.1661],\n",
      "        [0.1576, 0.1600, 0.1892, 0.1437, 0.1947, 0.1548],\n",
      "        [0.1851, 0.1628, 0.1696, 0.1672, 0.1590, 0.1564],\n",
      "        [0.1682, 0.1763, 0.1806, 0.1433, 0.1647, 0.1668],\n",
      "        [0.1855, 0.1463, 0.1805, 0.1685, 0.1582, 0.1610],\n",
      "        [0.1653, 0.1868, 0.1778, 0.1636, 0.1362, 0.1704],\n",
      "        [0.1676, 0.1805, 0.1579, 0.1579, 0.1551, 0.1810],\n",
      "        [0.1552, 0.1729, 0.1830, 0.1495, 0.1753, 0.1641],\n",
      "        [0.1702, 0.1810, 0.1611, 0.1734, 0.1543, 0.1601],\n",
      "        [0.1603, 0.1805, 0.1686, 0.1625, 0.1728, 0.1553],\n",
      "        [0.1624, 0.1689, 0.1748, 0.1611, 0.1707, 0.1620],\n",
      "        [0.1983, 0.1545, 0.1671, 0.1511, 0.1539, 0.1752],\n",
      "        [0.1478, 0.1755, 0.1560, 0.1710, 0.1627, 0.1869],\n",
      "        [0.1748, 0.1767, 0.1681, 0.1530, 0.1545, 0.1729],\n",
      "        [0.1951, 0.1376, 0.1734, 0.1914, 0.1441, 0.1583],\n",
      "        [0.2067, 0.1312, 0.1600, 0.1776, 0.1454, 0.1792],\n",
      "        [0.1811, 0.1506, 0.1671, 0.1764, 0.1560, 0.1687],\n",
      "        [0.1642, 0.1744, 0.1707, 0.1435, 0.1734, 0.1738]],\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "torch.Size([50, 6])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1675, 0.1677, 0.1683, 0.1647, 0.1731, 0.1586],\n",
      "        [0.1658, 0.1642, 0.1669, 0.1528, 0.1827, 0.1676],\n",
      "        [0.1868, 0.1388, 0.1645, 0.1561, 0.1883, 0.1655],\n",
      "        [0.1850, 0.1652, 0.1503, 0.1627, 0.1887, 0.1481],\n",
      "        [0.1884, 0.1419, 0.1480, 0.1715, 0.1819, 0.1682],\n",
      "        [0.1717, 0.1496, 0.1590, 0.1719, 0.1730, 0.1747],\n",
      "        [0.1620, 0.1588, 0.1646, 0.1659, 0.1919, 0.1568],\n",
      "        [0.1890, 0.1516, 0.1731, 0.1488, 0.1826, 0.1549],\n",
      "        [0.1954, 0.1307, 0.1747, 0.1573, 0.1898, 0.1520],\n",
      "        [0.1967, 0.1481, 0.1554, 0.1586, 0.1708, 0.1705],\n",
      "        [0.1889, 0.1727, 0.1492, 0.1692, 0.1742, 0.1458],\n",
      "        [0.1714, 0.1552, 0.1869, 0.1420, 0.1712, 0.1733],\n",
      "        [0.1754, 0.1494, 0.1563, 0.1770, 0.1840, 0.1579],\n",
      "        [0.1675, 0.1509, 0.1756, 0.1800, 0.1866, 0.1395],\n",
      "        [0.1810, 0.1537, 0.1698, 0.1727, 0.1656, 0.1572],\n",
      "        [0.1735, 0.1285, 0.1804, 0.1739, 0.1801, 0.1636],\n",
      "        [0.1798, 0.1640, 0.1727, 0.1643, 0.1720, 0.1472],\n",
      "        [0.1650, 0.1612, 0.1980, 0.1492, 0.1768, 0.1497],\n",
      "        [0.1768, 0.1404, 0.1750, 0.1818, 0.1790, 0.1470],\n",
      "        [0.1722, 0.1541, 0.1627, 0.1573, 0.1804, 0.1733],\n",
      "        [0.1768, 0.1647, 0.1600, 0.1559, 0.1802, 0.1624],\n",
      "        [0.1702, 0.1295, 0.1715, 0.1720, 0.1937, 0.1631],\n",
      "        [0.1722, 0.1539, 0.1838, 0.1615, 0.1743, 0.1543],\n",
      "        [0.1962, 0.1411, 0.1724, 0.1508, 0.1899, 0.1497],\n",
      "        [0.1836, 0.1652, 0.1684, 0.1590, 0.1805, 0.1433],\n",
      "        [0.1614, 0.1503, 0.1654, 0.1693, 0.2024, 0.1512],\n",
      "        [0.2036, 0.1523, 0.1559, 0.1426, 0.1910, 0.1545],\n",
      "        [0.1875, 0.1412, 0.1811, 0.1618, 0.1777, 0.1507],\n",
      "        [0.1617, 0.1408, 0.1660, 0.1773, 0.2167, 0.1375],\n",
      "        [0.1734, 0.1541, 0.1854, 0.1555, 0.1738, 0.1578],\n",
      "        [0.1821, 0.1418, 0.1770, 0.1523, 0.1837, 0.1631],\n",
      "        [0.1731, 0.1676, 0.1688, 0.1637, 0.1796, 0.1472],\n",
      "        [0.1825, 0.1563, 0.1613, 0.1506, 0.1981, 0.1512],\n",
      "        [0.1803, 0.1233, 0.1908, 0.1630, 0.1889, 0.1537],\n",
      "        [0.2145, 0.1586, 0.1485, 0.1546, 0.1767, 0.1471],\n",
      "        [0.1927, 0.1490, 0.1635, 0.1670, 0.1681, 0.1596],\n",
      "        [0.2030, 0.1486, 0.1662, 0.1364, 0.1889, 0.1570],\n",
      "        [0.1759, 0.1333, 0.1936, 0.1713, 0.1705, 0.1555],\n",
      "        [0.1836, 0.1434, 0.1585, 0.1547, 0.1861, 0.1736],\n",
      "        [0.1987, 0.1491, 0.1504, 0.1621, 0.1708, 0.1689],\n",
      "        [0.1877, 0.1483, 0.1825, 0.1517, 0.1748, 0.1551],\n",
      "        [0.1749, 0.1668, 0.1466, 0.1670, 0.1835, 0.1611],\n",
      "        [0.1864, 0.1600, 0.1795, 0.1450, 0.1590, 0.1700],\n",
      "        [0.1858, 0.1666, 0.1539, 0.1696, 0.1642, 0.1599],\n",
      "        [0.1995, 0.1399, 0.1744, 0.1485, 0.1760, 0.1617],\n",
      "        [0.1821, 0.1528, 0.1599, 0.1660, 0.1923, 0.1469],\n",
      "        [0.1718, 0.1401, 0.1713, 0.1608, 0.1857, 0.1704],\n",
      "        [0.1935, 0.1423, 0.1590, 0.1660, 0.1851, 0.1542],\n",
      "        [0.1854, 0.1475, 0.1745, 0.1612, 0.1865, 0.1449],\n",
      "        [0.1721, 0.1355, 0.1849, 0.1619, 0.1861, 0.1594]],\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "torch.Size([50, 6])\n"
     ]
    }
   ],
   "source": [
    "dataDir = '../data/pytorch' # folder to store our data\n",
    "trainSample = pd.read_csv(os.path.join(dataDir, 'train.csv'), header=None, names=None, nrows=500)\n",
    "trainSampleY = torch.from_numpy(trainSample[[0]].values).float().squeeze()\n",
    "trainSampleX = torch.from_numpy(trainSample.drop([0], axis = 1).values).long()\n",
    "\n",
    "# Build the dataset\n",
    "trainSampleDS = torch.utils.data.TensorDataset(trainSampleX, trainSampleY)\n",
    "# Build the dataloader\n",
    "trainSampleDL = torch.utils.data.DataLoader(trainSampleDS, batch_size=50)\n",
    "\n",
    "# Train the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ConvNet(10).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for bt in trainSampleDL:\n",
    "    bX, bY = bt\n",
    "\n",
    "    bX = bX.to(device)\n",
    "    bY = bY.to(device)\n",
    "\n",
    "    model = LSTMClassifier(100, 100, 50000).to(device)\n",
    "    optimizer.zero_grad()\n",
    "    output = model(bX)\n",
    "    print(output)\n",
    "    print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>492</th>\n",
       "      <th>493</th>\n",
       "      <th>494</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "      <th>500</th>\n",
       "      <th>501</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>146</td>\n",
       "      <td>1633</td>\n",
       "      <td>2529</td>\n",
       "      <td>3</td>\n",
       "      <td>1634</td>\n",
       "      <td>63</td>\n",
       "      <td>494</td>\n",
       "      <td>833</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>117</td>\n",
       "      <td>17</td>\n",
       "      <td>237</td>\n",
       "      <td>2125</td>\n",
       "      <td>110</td>\n",
       "      <td>2</td>\n",
       "      <td>203</td>\n",
       "      <td>69</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2530</td>\n",
       "      <td>2126</td>\n",
       "      <td>1459</td>\n",
       "      <td>624</td>\n",
       "      <td>2531</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>268</td>\n",
       "      <td>344</td>\n",
       "      <td>3</td>\n",
       "      <td>1460</td>\n",
       "      <td>8</td>\n",
       "      <td>127</td>\n",
       "      <td>51</td>\n",
       "      <td>199</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>1462</td>\n",
       "      <td>835</td>\n",
       "      <td>3206</td>\n",
       "      <td>1057</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>1463</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>495</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>847</td>\n",
       "      <td>1564</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>496</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>706</td>\n",
       "      <td>36</td>\n",
       "      <td>1105</td>\n",
       "      <td>2294</td>\n",
       "      <td>1740</td>\n",
       "      <td>1966</td>\n",
       "      <td>138</td>\n",
       "      <td>1245</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>497</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2296</td>\n",
       "      <td>436</td>\n",
       "      <td>1246</td>\n",
       "      <td>18</td>\n",
       "      <td>1128</td>\n",
       "      <td>758</td>\n",
       "      <td>3527</td>\n",
       "      <td>4956</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>498</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>127</td>\n",
       "      <td>17</td>\n",
       "      <td>1741</td>\n",
       "      <td>1742</td>\n",
       "      <td>2</td>\n",
       "      <td>334</td>\n",
       "      <td>815</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>499</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>632</td>\n",
       "      <td>159</td>\n",
       "      <td>537</td>\n",
       "      <td>66</td>\n",
       "      <td>904</td>\n",
       "      <td>1483</td>\n",
       "      <td>141</td>\n",
       "      <td>3528</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 502 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1     2     3     4     5     6     7     8     9    ...  492  493  \\\n",
       "0      4    9   146  1633  2529     3  1634    63   494   833  ...    0    0   \n",
       "1      2   11   117    17   237  2125   110     2   203    69  ...    0    0   \n",
       "2      4    5  2530  2126  1459   624  2531     0     0     0  ...    0    0   \n",
       "3      1   18   268   344     3  1460     8   127    51   199  ...    0    0   \n",
       "4      0   25  1462   835  3206  1057    37     5  1463    37  ...    0    0   \n",
       "..   ...  ...   ...   ...   ...   ...   ...   ...   ...   ...  ...  ...  ...   \n",
       "495    0    2   847  1564     0     0     0     0     0     0  ...    0    0   \n",
       "496    1   24   706    36  1105  2294  1740  1966   138  1245  ...    0    0   \n",
       "497    1   12  2296   436  1246    18  1128   758  3527  4956  ...    0    0   \n",
       "498    2    7   127    17  1741  1742     2   334   815     0  ...    0    0   \n",
       "499    5   15   632   159   537    66   904  1483   141  3528  ...    0    0   \n",
       "\n",
       "     494  495  496  497  498  499  500  501  \n",
       "0      0    0    0    0    0    0    0    0  \n",
       "1      0    0    0    0    0    0    0    0  \n",
       "2      0    0    0    0    0    0    0    0  \n",
       "3      0    0    0    0    0    0    0    0  \n",
       "4      0    0    0    0    0    0    0    0  \n",
       "..   ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "495    0    0    0    0    0    0    0    0  \n",
       "496    0    0    0    0    0    0    0    0  \n",
       "497    0    0    0    0    0    0    0    0  \n",
       "498    0    0    0    0    0    0    0    0  \n",
       "499    0    0    0    0    0    0    0    0  \n",
       "\n",
       "[500 rows x 502 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainSample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataLoader' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-a54acb85ba09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainSampleDL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataLoader' object has no attribute 'shape'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    This is the simple RNN model we will be using to perform Sentiment Analysis.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size):\n",
    "        \"\"\"\n",
    "        Initialize the model by settingg up the various layers.\n",
    "        \"\"\"\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
    "        self.dense = nn.Linear(in_features=hidden_dim, out_features=6)\n",
    "        self.sm = nn.Softmax(dim = 1)\n",
    "        \n",
    "        self.word_dict = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Perform a forward pass of our model on some input.\n",
    "        \"\"\"\n",
    "        x = x.t()\n",
    "        lengths = x[0,:]\n",
    "        text = x[1:,:]\n",
    "        embeds = self.embedding(text)\n",
    "        lstm_out, _ = self.lstm(embeds)\n",
    "        out = self.dense(lstm_out)\n",
    "        out = out[lengths - 1, range(len(lengths))]\n",
    "        return self.sm(out.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
